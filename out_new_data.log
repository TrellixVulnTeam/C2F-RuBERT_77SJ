2022-05-15 01:14:45,885 - INFO - allennlp.common.params - random_seed = 13370
2022-05-15 01:14:45,885 - INFO - allennlp.common.params - numpy_seed = 1337
2022-05-15 01:14:45,885 - INFO - allennlp.common.params - pytorch_seed = 133
2022-05-15 01:14:45,886 - INFO - allennlp.common.checks - Pytorch version: 1.9.0+cu111
2022-05-15 01:14:45,886 - INFO - allennlp.common.params - type = default
2022-05-15 01:14:45,887 - INFO - allennlp.common.params - dataset_reader.type = coref
2022-05-15 01:14:45,887 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-05-15 01:14:45,887 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2022-05-15 01:14:45,887 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False
2022-05-15 01:14:45,887 - INFO - allennlp.common.params - dataset_reader.max_span_width = 20
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = DeepPavlov/rubert-base-cased
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 128
2022-05-15 01:14:45,888 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2022-05-15 01:14:52,224 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None
2022-05-15 01:14:52,224 - INFO - allennlp.common.params - dataset_reader.max_sentences = None
2022-05-15 01:14:52,224 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = False
2022-05-15 01:14:52,224 - INFO - allennlp.common.params - train_data_path = /home/glebg/coref_russian/data/train.conll
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fc5192f6b50>
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - validation_data_path = /home/glebg/coref_russian/data/dev.conll
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - validation_data_loader = None
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - test_data_path = /home/glebg/coref_russian/data/test.conll
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - evaluate_on_test = False
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - batch_weight_key = 
2022-05-15 01:14:52,225 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-05-15 01:14:52,226 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-05-15 01:14:52,227 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-05-15 01:15:02,373 - INFO - tqdm - loading instances: 343it [00:10, 28.43it/s]
2022-05-15 01:15:12,391 - INFO - tqdm - loading instances: 760it [00:20, 116.62it/s]
2022-05-15 01:15:14,003 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-05-15 01:15:14,003 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-05-15 01:15:14,004 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-05-15 01:15:14,005 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-05-15 01:15:17,277 - INFO - allennlp.common.params - data_loader.type = multiprocess
2022-05-15 01:15:17,277 - INFO - allennlp.common.params - data_loader.batch_size = None
2022-05-15 01:15:17,277 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-05-15 01:15:17,277 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 1
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.start_method = fork
2022-05-15 01:15:17,278 - INFO - allennlp.common.params - data_loader.cuda_device = None
2022-05-15 01:15:17,278 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2022-05-15 01:15:18,842 - INFO - allennlp.common.params - type = from_instances
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - min_count = None
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - max_vocab_size = None
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - pretrained_files = None
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - only_include_pretrained_words = False
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - tokens_to_add = None
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2022-05-15 01:15:18,843 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2022-05-15 01:15:18,843 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-05-15 01:15:18,843 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2022-05-15 01:15:19,696 - INFO - allennlp.common.params - model.type = coref
2022-05-15 01:15:19,696 - INFO - allennlp.common.params - model.regularizer = None
2022-05-15 01:15:19,696 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = DeepPavlov/rubert-base-cased
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 128
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None
2022-05-15 01:15:19,697 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.type = lstm
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.input_size = 768
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.hidden_size = 200
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.num_layers = 1
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.bias = True
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.dropout = 0.0
2022-05-15 01:15:34,183 - INFO - allennlp.common.params - model.context_layer.bidirectional = True
2022-05-15 01:15:34,184 - INFO - allennlp.common.params - model.context_layer.stateful = False
2022-05-15 01:15:34,191 - INFO - allennlp.common.params - model.mention_feedforward.input_dim = 1588
2022-05-15 01:15:34,191 - INFO - allennlp.common.params - model.mention_feedforward.num_layers = 2
2022-05-15 01:15:34,191 - INFO - allennlp.common.params - model.mention_feedforward.hidden_dims = 150
2022-05-15 01:15:34,191 - INFO - allennlp.common.params - model.mention_feedforward.activations = relu
2022-05-15 01:15:34,191 - INFO - allennlp.common.params - type = relu
2022-05-15 01:15:34,192 - INFO - allennlp.common.params - model.mention_feedforward.dropout = 0.2
2022-05-15 01:15:34,193 - INFO - allennlp.common.params - model.antecedent_feedforward.input_dim = 4784
2022-05-15 01:15:34,193 - INFO - allennlp.common.params - model.antecedent_feedforward.num_layers = 2
2022-05-15 01:15:34,194 - INFO - allennlp.common.params - model.antecedent_feedforward.hidden_dims = 150
2022-05-15 01:15:34,194 - INFO - allennlp.common.params - model.antecedent_feedforward.activations = relu
2022-05-15 01:15:34,194 - INFO - allennlp.common.params - type = relu
2022-05-15 01:15:34,194 - INFO - allennlp.common.params - model.antecedent_feedforward.dropout = 0.2
2022-05-15 01:15:34,197 - INFO - allennlp.common.params - model.feature_size = 20
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.max_span_width = 20
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.spans_per_word = 0.4
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.max_antecedents = 150
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.coarse_to_fine = False
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.inference_order = 1
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.lexical_dropout = 0.5
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal
2022-05-15 01:15:34,198 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.1.1.type = xavier_normal
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.1.1.gain = 1.0
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.2.1.type = xavier_normal
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.2.1.gain = 1.0
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.3.1.type = xavier_normal
2022-05-15 01:15:34,199 - INFO - allennlp.common.params - model.initializer.regexes.3.1.gain = 1.0
2022-05-15 01:15:34,200 - INFO - allennlp.common.params - model.initializer.regexes.4.1.type = xavier_normal
2022-05-15 01:15:34,200 - INFO - allennlp.common.params - model.initializer.regexes.4.1.gain = 1.0
2022-05-15 01:15:34,200 - INFO - allennlp.common.params - model.initializer.regexes.5.1.type = orthogonal
2022-05-15 01:15:34,200 - INFO - allennlp.common.params - model.initializer.regexes.5.1.gain = 1.0
2022-05-15 01:15:34,200 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None
2022-05-15 01:15:34,201 - INFO - allennlp.nn.initializers - Initializing parameters
2022-05-15 01:15:34,208 - INFO - allennlp.nn.initializers - Initializing _context_layer._module.weight_ih_l0 using _context_layer._module.weight_ih.* initializer
2022-05-15 01:15:34,211 - INFO - allennlp.nn.initializers - Initializing _context_layer._module.weight_hh_l0 using _context_layer._module.weight_hh.* initializer
2022-05-15 01:15:34,219 - INFO - allennlp.nn.initializers - Initializing _context_layer._module.weight_ih_l0_reverse using _context_layer._module.weight_ih.* initializer
2022-05-15 01:15:34,223 - INFO - allennlp.nn.initializers - Initializing _context_layer._module.weight_hh_l0_reverse using _context_layer._module.weight_hh.* initializer
2022-05-15 01:15:34,228 - INFO - allennlp.nn.initializers - Initializing _mention_feedforward._module._linear_layers.0.weight using .*linear_layers.*weight initializer
2022-05-15 01:15:34,230 - INFO - allennlp.nn.initializers - Initializing _mention_feedforward._module._linear_layers.1.weight using .*linear_layers.*weight initializer
2022-05-15 01:15:34,230 - INFO - allennlp.nn.initializers - Initializing _mention_scorer._module.weight using .*scorer._module.weight initializer
2022-05-15 01:15:34,230 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.0.weight using .*linear_layers.*weight initializer
2022-05-15 01:15:34,234 - INFO - allennlp.nn.initializers - Initializing _antecedent_feedforward._module._linear_layers.1.weight using .*linear_layers.*weight initializer
2022-05-15 01:15:34,234 - INFO - allennlp.nn.initializers - Initializing _antecedent_scorer._module.weight using .*scorer._module.weight initializer
2022-05-15 01:15:34,234 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer
2022-05-15 01:15:34,234 - INFO - allennlp.nn.initializers - Initializing _distance_embedding.weight using _distance_embedding.weight initializer
2022-05-15 01:15:34,234 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.weight
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _context_layer._module.bias_hh_l0
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _context_layer._module.bias_hh_l0_reverse
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _context_layer._module.bias_ih_l0
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _context_layer._module.bias_ih_l0_reverse
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _mention_scorer._module.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-05-15 01:15:34,235 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-05-15 01:15:34,236 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-05-15 01:15:34,237 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-05-15 01:15:34,238 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-05-15 01:15:34,239 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-05-15 01:15:34,240 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-05-15 01:15:34,241 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-05-15 01:15:34,242 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias
2022-05-15 01:15:34,243 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight
2022-05-15 01:15:57,255 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.patience = 30
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.validation_metric = +coref_f1
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.num_epochs = 150
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.cuda_device = None
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.grad_norm = 5
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.distributed = False
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.world_size = 1
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.use_amp = False
2022-05-15 01:15:57,256 - INFO - allennlp.common.params - trainer.no_grad = None
2022-05-15 01:15:57,257 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-05-15 01:15:57,257 - INFO - allennlp.common.params - trainer.moving_average = None
2022-05-15 01:15:57,257 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x7fc519357a90>
2022-05-15 01:15:57,257 - INFO - allennlp.common.params - trainer.callbacks = None
2022-05-15 01:15:57,257 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.type = huggingface_adamw
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.01
2022-05-15 01:16:00,152 - INFO - allennlp.common.params - trainer.optimizer.correct_bias = True
2022-05-15 01:16:00,153 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2022-05-15 01:16:00,153 - INFO - allennlp.training.optimizers - Group 0: ['_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight'], {'lr': 1e-05}
2022-05-15 01:16:00,154 - INFO - allennlp.training.optimizers - Group 1: ['_context_layer._module.weight_hh_l0_reverse', '_attentive_span_extractor._global_attention._module.weight', '_context_layer._module.bias_ih_l0', '_antecedent_feedforward._module._linear_layers.0.weight', '_mention_feedforward._module._linear_layers.0.bias', '_context_layer._module.weight_ih_l0', '_antecedent_feedforward._module._linear_layers.1.bias', '_context_layer._module.bias_ih_l0_reverse', '_context_layer._module.weight_ih_l0_reverse', '_antecedent_scorer._module.bias', '_attentive_span_extractor._global_attention._module.bias', '_mention_feedforward._module._linear_layers.1.weight', '_endpoint_span_extractor._span_width_embedding.weight', '_antecedent_feedforward._module._linear_layers.1.weight', '_mention_scorer._module.bias', '_antecedent_feedforward._module._linear_layers.0.bias', '_antecedent_scorer._module.weight', '_context_layer._module.bias_hh_l0', '_distance_embedding.weight', '_mention_feedforward._module._linear_layers.1.bias', '_context_layer._module.bias_hh_l0_reverse', '_mention_feedforward._module._linear_layers.0.weight', '_context_layer._module.weight_hh_l0', '_mention_scorer._module.weight'], {}
2022-05-15 01:16:00,154 - INFO - allennlp.training.optimizers - Number of trainable parameters: 180408511
2022-05-15 01:16:00,154 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight
2022-05-15 01:16:00,155 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-15 01:16:00,156 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight
2022-05-15 01:16:00,157 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight
2022-05-15 01:16:00,158 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias
2022-05-15 01:16:00,159 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias
2022-05-15 01:16:00,160 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias
2022-05-15 01:16:00,161 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias
2022-05-15 01:16:00,162 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias
2022-05-15 01:16:00,163 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.weight_ih_l0
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.weight_hh_l0
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.bias_ih_l0
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.bias_hh_l0
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.weight_ih_l0_reverse
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.weight_hh_l0_reverse
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.bias_ih_l0_reverse
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _context_layer._module.bias_hh_l0_reverse
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.0.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.0.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.1.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_feedforward._module._linear_layers.1.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_scorer._module.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _mention_scorer._module.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.0.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.0.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.1.weight
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _antecedent_feedforward._module._linear_layers.1.bias
2022-05-15 01:16:00,164 - INFO - allennlp.common.util - _antecedent_scorer._module.weight
2022-05-15 01:16:00,165 - INFO - allennlp.common.util - _antecedent_scorer._module.bias
2022-05-15 01:16:00,165 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight
2022-05-15 01:16:00,165 - INFO - allennlp.common.util - _attentive_span_extractor._global_attention._module.weight
2022-05-15 01:16:00,165 - INFO - allennlp.common.util - _attentive_span_extractor._global_attention._module.bias
2022-05-15 01:16:00,165 - INFO - allennlp.common.util - _distance_embedding.weight
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = reduce_on_plateau
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.mode = max
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 0.5
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.patience = 2
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.verbose = False
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold_mode = rel
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold = 0.0001
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cooldown = 0
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.min_lr = 0
2022-05-15 01:16:00,165 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.eps = 1e-08
2022-05-15 01:16:00,166 - INFO - allennlp.common.params - type = default
2022-05-15 01:16:00,166 - INFO - allennlp.common.params - keep_serialized_model_every_num_seconds = None
2022-05-15 01:16:00,166 - INFO - allennlp.common.params - num_serialized_models_to_keep = 2
2022-05-15 01:16:00,166 - INFO - allennlp.common.params - model_save_interval = None
2022-05-15 01:16:00,167 - INFO - allennlp.training.trainer - Beginning training.
2022-05-15 01:16:00,167 - INFO - allennlp.training.trainer - Epoch 0/149
2022-05-15 01:16:00,167 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.2G
2022-05-15 01:16:00,168 - INFO - allennlp.training.trainer - GPU 0 memory usage: 691M
2022-05-15 01:16:00,168 - INFO - allennlp.training.trainer - Training
2022-05-15 01:16:00,169 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:16:10,347 - INFO - tqdm - coref_precision: 0.0175, coref_recall: 0.0024, coref_f1: 0.0032, mention_recall: 0.1730, batch_loss: 17.2541, loss: 67.3256 ||:   9%|9         | 93/998 [00:10<01:30,  9.97it/s]
2022-05-15 01:16:20,577 - INFO - tqdm - coref_precision: 0.2192, coref_recall: 0.0184, coref_f1: 0.0327, mention_recall: 0.4996, batch_loss: 79.5773, loss: 63.1721 ||:  18%|#7        | 178/998 [00:20<01:33,  8.78it/s]
2022-05-15 01:16:30,748 - INFO - tqdm - coref_precision: 0.4029, coref_recall: 0.0744, coref_f1: 0.1236, mention_recall: 0.6311, batch_loss: 165.1081, loss: 60.0412 ||:  26%|##6       | 264/998 [00:30<01:07, 10.88it/s]
2022-05-15 01:16:40,771 - INFO - tqdm - coref_precision: 0.4613, coref_recall: 0.1099, coref_f1: 0.1745, mention_recall: 0.6995, batch_loss: 61.0864, loss: 53.1675 ||:  36%|###6      | 361/998 [00:40<01:24,  7.58it/s]
2022-05-15 01:16:52,484 - INFO - tqdm - coref_precision: 0.4759, coref_recall: 0.1420, coref_f1: 0.2152, mention_recall: 0.7574, batch_loss: 648.6865, loss: 56.1388 ||:  43%|####2     | 425/998 [00:52<06:02,  1.58it/s]
2022-05-15 01:17:02,667 - INFO - tqdm - coref_precision: 0.5073, coref_recall: 0.1637, coref_f1: 0.2439, mention_recall: 0.7912, batch_loss: 31.8210, loss: 52.2315 ||:  52%|#####2    | 520/998 [01:02<00:48,  9.89it/s]
2022-05-15 01:17:12,875 - INFO - tqdm - coref_precision: 0.5456, coref_recall: 0.1989, coref_f1: 0.2871, mention_recall: 0.8197, batch_loss: 105.8099, loss: 49.0242 ||:  62%|######1   | 618/998 [01:12<00:46,  8.21it/s]
2022-05-15 01:17:22,885 - INFO - tqdm - coref_precision: 0.5601, coref_recall: 0.2119, coref_f1: 0.3029, mention_recall: 0.8357, batch_loss: 0.3735, loss: 46.7458 ||:  71%|#######1  | 712/998 [01:22<00:21, 13.59it/s]
2022-05-15 01:17:33,154 - INFO - tqdm - coref_precision: 0.5703, coref_recall: 0.2232, coref_f1: 0.3159, mention_recall: 0.8434, batch_loss: 18.7542, loss: 44.3831 ||:  80%|########  | 800/998 [01:32<00:29,  6.82it/s]
2022-05-15 01:17:43,507 - INFO - tqdm - coref_precision: 0.5801, coref_recall: 0.2389, coref_f1: 0.3331, mention_recall: 0.8587, batch_loss: 0.0017, loss: 44.2489 ||:  88%|########8 | 880/998 [01:43<00:33,  3.50it/s]
2022-05-15 01:17:53,749 - INFO - tqdm - coref_precision: 0.5831, coref_recall: 0.2505, coref_f1: 0.3453, mention_recall: 0.8614, batch_loss: 17.8815, loss: 44.5608 ||:  97%|#########6| 964/998 [01:53<00:03,  9.67it/s]
2022-05-15 01:17:58,225 - INFO - tqdm - coref_precision: 0.5852, coref_recall: 0.2530, coref_f1: 0.3481, mention_recall: 0.8653, batch_loss: 0.0524, loss: 44.2170 ||: 100%|#########9| 994/998 [01:58<00:00,  8.49it/s]
2022-05-15 01:17:58,468 - INFO - tqdm - coref_precision: 0.5853, coref_recall: 0.2531, coref_f1: 0.3482, mention_recall: 0.8655, batch_loss: 27.5733, loss: 44.1986 ||: 100%|#########9| 996/998 [01:58<00:00,  8.41it/s]
2022-05-15 01:17:58,592 - INFO - tqdm - coref_precision: 0.5854, coref_recall: 0.2532, coref_f1: 0.3483, mention_recall: 0.8655, batch_loss: 0.6942, loss: 44.1107 ||: 100%|##########| 998/998 [01:58<00:00,  9.91it/s]
2022-05-15 01:17:58,593 - INFO - tqdm - coref_precision: 0.5854, coref_recall: 0.2532, coref_f1: 0.3483, mention_recall: 0.8655, batch_loss: 0.6942, loss: 44.1107 ||: 100%|##########| 998/998 [01:58<00:00,  8.43it/s]
2022-05-15 01:17:59,542 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:17:59,544 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:18:06,134 - INFO - tqdm - coref_precision: 0.6837, coref_recall: 0.3328, coref_f1: 0.4442, mention_recall: 0.9120, batch_loss: 27.3500, loss: 34.8813 ||: 100%|##########| 122/122 [00:06<00:00, 18.51it/s]
2022-05-15 01:18:08,001 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.348  |     0.444
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.585  |     0.684
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.253  |     0.333
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   690.568  |       N/A
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - loss               |    44.111  |    34.881
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.865  |     0.912
2022-05-15 01:18:08,370 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7342.535  |       N/A
2022-05-15 01:18:08,370 - INFO - allennlp.training.trainer - Epoch duration: 0:02:08.203030
2022-05-15 01:18:08,371 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:18:22
2022-05-15 01:18:08,371 - INFO - allennlp.training.trainer - Epoch 1/149
2022-05-15 01:18:08,371 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:18:08,371 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:18:08,372 - INFO - allennlp.training.trainer - Training
2022-05-15 01:18:08,372 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:18:18,854 - INFO - tqdm - coref_precision: 0.6538, coref_recall: 0.3969, coref_f1: 0.4867, mention_recall: 0.9594, batch_loss: 197.1120, loss: 27.9346 ||:   8%|8         | 83/998 [00:10<04:04,  3.75it/s]
2022-05-15 01:18:29,089 - INFO - tqdm - coref_precision: 0.6603, coref_recall: 0.3965, coref_f1: 0.4870, mention_recall: 0.9725, batch_loss: 41.7987, loss: 28.3665 ||:  17%|#7        | 170/998 [00:20<01:44,  7.90it/s]
2022-05-15 01:18:39,136 - INFO - tqdm - coref_precision: 0.6618, coref_recall: 0.4105, coref_f1: 0.4999, mention_recall: 0.9789, batch_loss: 0.0050, loss: 28.3932 ||:  26%|##6       | 261/998 [00:30<01:11, 10.30it/s]
2022-05-15 01:18:49,152 - INFO - tqdm - coref_precision: 0.6572, coref_recall: 0.4158, coref_f1: 0.5027, mention_recall: 0.9770, batch_loss: 1.5498, loss: 32.4899 ||:  34%|###3      | 335/998 [00:40<01:30,  7.29it/s]
2022-05-15 01:18:59,268 - INFO - tqdm - coref_precision: 0.6587, coref_recall: 0.4024, coref_f1: 0.4932, mention_recall: 0.9583, batch_loss: 2.1921, loss: 33.0498 ||:  43%|####2     | 426/998 [00:50<01:08,  8.38it/s]
2022-05-15 01:19:09,304 - INFO - tqdm - coref_precision: 0.6666, coref_recall: 0.4187, coref_f1: 0.5075, mention_recall: 0.9639, batch_loss: 3.7805, loss: 31.6244 ||:  52%|#####1    | 514/998 [01:00<01:04,  7.45it/s]
2022-05-15 01:19:19,320 - INFO - tqdm - coref_precision: 0.6709, coref_recall: 0.4255, coref_f1: 0.5141, mention_recall: 0.9660, batch_loss: 0.6914, loss: 31.8945 ||:  61%|######    | 605/998 [01:10<01:04,  6.12it/s]
2022-05-15 01:19:29,430 - INFO - tqdm - coref_precision: 0.6748, coref_recall: 0.4186, coref_f1: 0.5109, mention_recall: 0.9582, batch_loss: 3.1896, loss: 33.1641 ||:  68%|######8   | 681/998 [01:21<00:35,  9.02it/s]
2022-05-15 01:19:39,496 - INFO - tqdm - coref_precision: 0.6751, coref_recall: 0.4197, coref_f1: 0.5117, mention_recall: 0.9613, batch_loss: 7.2909, loss: 32.7215 ||:  76%|#######6  | 759/998 [01:31<00:25,  9.27it/s]
2022-05-15 01:19:49,619 - INFO - tqdm - coref_precision: 0.6801, coref_recall: 0.4266, coref_f1: 0.5182, mention_recall: 0.9644, batch_loss: 4.0876, loss: 31.2111 ||:  86%|########6 | 859/998 [01:41<00:12, 11.28it/s]
2022-05-15 01:19:59,773 - INFO - tqdm - coref_precision: 0.6803, coref_recall: 0.4267, coref_f1: 0.5185, mention_recall: 0.9666, batch_loss: 3.2386, loss: 31.0351 ||:  95%|#########5| 952/998 [01:51<00:08,  5.19it/s]
2022-05-15 01:20:05,851 - INFO - tqdm - coref_precision: 0.6780, coref_recall: 0.4242, coref_f1: 0.5161, mention_recall: 0.9663, batch_loss: 55.5067, loss: 31.2261 ||: 100%|#########9| 994/998 [01:57<00:00, 10.72it/s]
2022-05-15 01:20:06,000 - INFO - tqdm - coref_precision: 0.6785, coref_recall: 0.4246, coref_f1: 0.5165, mention_recall: 0.9663, batch_loss: 11.6390, loss: 31.1826 ||: 100%|#########9| 996/998 [01:57<00:00, 11.44it/s]
2022-05-15 01:20:06,563 - INFO - tqdm - coref_precision: 0.6788, coref_recall: 0.4236, coref_f1: 0.5158, mention_recall: 0.9662, batch_loss: 0.0006, loss: 31.2712 ||: 100%|##########| 998/998 [01:58<00:00,  6.82it/s]
2022-05-15 01:20:06,564 - INFO - tqdm - coref_precision: 0.6788, coref_recall: 0.4236, coref_f1: 0.5158, mention_recall: 0.9662, batch_loss: 0.0006, loss: 31.2712 ||: 100%|##########| 998/998 [01:58<00:00,  8.44it/s]
2022-05-15 01:20:07,510 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:20:07,512 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:20:14,167 - INFO - tqdm - coref_precision: 0.7055, coref_recall: 0.3947, coref_f1: 0.5017, mention_recall: 0.9399, batch_loss: 31.4575, loss: 37.1078 ||: 100%|##########| 122/122 [00:06<00:00, 23.69it/s]
2022-05-15 01:20:14,167 - INFO - tqdm - coref_precision: 0.7055, coref_recall: 0.3947, coref_f1: 0.5017, mention_recall: 0.9399, batch_loss: 31.4575, loss: 37.1078 ||: 100%|##########| 122/122 [00:06<00:00, 18.33it/s]
2022-05-15 01:20:16,183 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:20:26,914 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:20:26,914 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.516  |     0.502
2022-05-15 01:20:26,914 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.679  |     0.706
2022-05-15 01:20:26,915 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.424  |     0.395
2022-05-15 01:20:26,915 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37462.975  |       N/A
2022-05-15 01:20:26,915 - INFO - allennlp.training.callbacks.console_logger - loss               |    31.271  |    37.108
2022-05-15 01:20:26,915 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.966  |     0.940
2022-05-15 01:20:26,915 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7596.719  |       N/A
2022-05-15 01:20:26,915 - INFO - allennlp.training.trainer - Epoch duration: 0:02:18.544272
2022-05-15 01:20:26,915 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:28:59
2022-05-15 01:20:26,915 - INFO - allennlp.training.trainer - Epoch 2/149
2022-05-15 01:20:26,915 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:20:26,916 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:20:26,916 - INFO - allennlp.training.trainer - Training
2022-05-15 01:20:26,917 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:20:36,985 - INFO - tqdm - coref_precision: 0.7337, coref_recall: 0.5457, coref_f1: 0.6183, mention_recall: 0.9742, batch_loss: 14.7699, loss: 26.3606 ||:   9%|8         | 89/998 [00:10<01:32,  9.81it/s]
2022-05-15 01:20:47,199 - INFO - tqdm - coref_precision: 0.7161, coref_recall: 0.5186, coref_f1: 0.5949, mention_recall: 0.9816, batch_loss: 146.4363, loss: 29.9526 ||:  16%|#6        | 160/998 [00:20<01:39,  8.40it/s]
2022-05-15 01:20:57,318 - INFO - tqdm - coref_precision: 0.7247, coref_recall: 0.5224, coref_f1: 0.5991, mention_recall: 0.9852, batch_loss: 0.2210, loss: 26.7584 ||:  24%|##4       | 242/998 [00:30<01:19,  9.48it/s]
2022-05-15 01:21:07,432 - INFO - tqdm - coref_precision: 0.7241, coref_recall: 0.5019, coref_f1: 0.5863, mention_recall: 0.9684, batch_loss: 1.9272, loss: 26.2370 ||:  34%|###3      | 336/998 [00:40<01:03, 10.38it/s]
2022-05-15 01:21:17,805 - INFO - tqdm - coref_precision: 0.7193, coref_recall: 0.5011, coref_f1: 0.5841, mention_recall: 0.9704, batch_loss: 2.8546, loss: 25.2899 ||:  43%|####3     | 432/998 [00:50<01:10,  8.02it/s]
2022-05-15 01:21:27,947 - INFO - tqdm - coref_precision: 0.7162, coref_recall: 0.5045, coref_f1: 0.5853, mention_recall: 0.9737, batch_loss: 1.2677, loss: 25.2919 ||:  52%|#####1    | 518/998 [01:01<00:52,  9.10it/s]
2022-05-15 01:21:37,994 - INFO - tqdm - coref_precision: 0.7144, coref_recall: 0.4870, coref_f1: 0.5735, mention_recall: 0.9664, batch_loss: 10.8592, loss: 27.6779 ||:  61%|######    | 604/998 [01:11<00:37, 10.49it/s]
2022-05-15 01:21:48,028 - INFO - tqdm - coref_precision: 0.7131, coref_recall: 0.4882, coref_f1: 0.5739, mention_recall: 0.9699, batch_loss: 2.4160, loss: 27.5323 ||:  69%|######9   | 690/998 [01:21<00:26, 11.58it/s]
2022-05-15 01:21:58,141 - INFO - tqdm - coref_precision: 0.7144, coref_recall: 0.4911, coref_f1: 0.5763, mention_recall: 0.9719, batch_loss: 91.1162, loss: 27.4481 ||:  78%|#######8  | 781/998 [01:31<00:28,  7.74it/s]
2022-05-15 01:22:08,161 - INFO - tqdm - coref_precision: 0.7163, coref_recall: 0.4950, coref_f1: 0.5798, mention_recall: 0.9744, batch_loss: 46.6209, loss: 27.0364 ||:  87%|########6 | 866/998 [01:41<00:11, 11.61it/s]
2022-05-15 01:22:18,669 - INFO - tqdm - coref_precision: 0.7114, coref_recall: 0.4887, coref_f1: 0.5742, mention_recall: 0.9760, batch_loss: 271.2304, loss: 27.6999 ||:  94%|#########4| 942/998 [01:51<00:08,  6.33it/s]
2022-05-15 01:22:24,427 - INFO - tqdm - coref_precision: 0.7111, coref_recall: 0.4900, coref_f1: 0.5750, mention_recall: 0.9768, batch_loss: 16.5667, loss: 27.4535 ||: 100%|#########9| 994/998 [01:57<00:00, 10.59it/s]
2022-05-15 01:22:24,581 - INFO - tqdm - coref_precision: 0.7113, coref_recall: 0.4902, coref_f1: 0.5752, mention_recall: 0.9768, batch_loss: 4.1052, loss: 27.4025 ||: 100%|#########9| 996/998 [01:57<00:00, 11.21it/s]
2022-05-15 01:22:24,863 - INFO - tqdm - coref_precision: 0.7110, coref_recall: 0.4898, coref_f1: 0.5748, mention_recall: 0.9769, batch_loss: 89.9241, loss: 27.4847 ||: 100%|##########| 998/998 [01:57<00:00,  9.54it/s]
2022-05-15 01:22:24,864 - INFO - tqdm - coref_precision: 0.7110, coref_recall: 0.4898, coref_f1: 0.5748, mention_recall: 0.9769, batch_loss: 89.9241, loss: 27.4847 ||: 100%|##########| 998/998 [01:57<00:00,  8.46it/s]
2022-05-15 01:22:26,316 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:22:26,318 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:22:32,943 - INFO - tqdm - coref_precision: 0.6648, coref_recall: 0.4850, coref_f1: 0.5536, mention_recall: 0.9920, batch_loss: 18.2430, loss: 42.1736 ||: 100%|##########| 122/122 [00:06<00:00, 18.41it/s]
2022-05-15 01:22:35,355 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.575  |     0.554
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.711  |     0.665
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.490  |     0.485
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.025  |       N/A
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - loss               |    27.485  |    42.174
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.977  |     0.992
2022-05-15 01:22:41,395 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7596.969  |       N/A
2022-05-15 01:22:41,395 - INFO - allennlp.training.trainer - Epoch duration: 0:02:14.480354
2022-05-15 01:22:41,396 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:27:40
2022-05-15 01:22:41,396 - INFO - allennlp.training.trainer - Epoch 3/149
2022-05-15 01:22:41,396 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:22:41,396 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:22:41,397 - INFO - allennlp.training.trainer - Training
2022-05-15 01:22:41,397 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:22:51,735 - INFO - tqdm - coref_precision: 0.7204, coref_recall: 0.4849, coref_f1: 0.5756, mention_recall: 0.9954, batch_loss: 282.3072, loss: 26.4878 ||:   8%|8         | 82/998 [00:10<02:37,  5.80it/s]
2022-05-15 01:23:01,748 - INFO - tqdm - coref_precision: 0.7324, coref_recall: 0.5269, coref_f1: 0.6084, mention_recall: 0.9936, batch_loss: 0.0000, loss: 23.7830 ||:  17%|#6        | 168/998 [00:20<01:37,  8.53it/s]
2022-05-15 01:23:11,894 - INFO - tqdm - coref_precision: 0.7445, coref_recall: 0.5498, coref_f1: 0.6269, mention_recall: 0.9940, batch_loss: 2.3189, loss: 21.9842 ||:  26%|##5       | 256/998 [00:30<01:20,  9.17it/s]
2022-05-15 01:23:21,999 - INFO - tqdm - coref_precision: 0.7277, coref_recall: 0.5434, coref_f1: 0.6170, mention_recall: 0.9940, batch_loss: 14.1850, loss: 24.2910 ||:  34%|###4      | 340/998 [00:40<01:15,  8.68it/s]
2022-05-15 01:23:32,033 - INFO - tqdm - coref_precision: 0.7317, coref_recall: 0.5412, coref_f1: 0.6172, mention_recall: 0.9918, batch_loss: 0.9689, loss: 24.0527 ||:  42%|####2     | 423/998 [00:50<01:25,  6.71it/s]
2022-05-15 01:23:42,638 - INFO - tqdm - coref_precision: 0.7306, coref_recall: 0.5430, coref_f1: 0.6177, mention_recall: 0.9916, batch_loss: 32.3064, loss: 23.0937 ||:  53%|#####2    | 524/998 [01:01<01:17,  6.08it/s]
2022-05-15 01:23:52,749 - INFO - tqdm - coref_precision: 0.7299, coref_recall: 0.5423, coref_f1: 0.6171, mention_recall: 0.9920, batch_loss: 0.8313, loss: 22.6260 ||:  60%|######    | 603/998 [01:11<00:40,  9.86it/s]
2022-05-15 01:24:02,914 - INFO - tqdm - coref_precision: 0.7315, coref_recall: 0.5439, coref_f1: 0.6183, mention_recall: 0.9913, batch_loss: 17.2776, loss: 23.4340 ||:  68%|######7   | 677/998 [01:21<00:36,  8.74it/s]
2022-05-15 01:24:13,068 - INFO - tqdm - coref_precision: 0.7374, coref_recall: 0.5491, coref_f1: 0.6234, mention_recall: 0.9908, batch_loss: 0.0059, loss: 23.4344 ||:  77%|#######7  | 773/998 [01:31<00:20, 11.25it/s]
2022-05-15 01:24:23,170 - INFO - tqdm - coref_precision: 0.7301, coref_recall: 0.5439, coref_f1: 0.6171, mention_recall: 0.9810, batch_loss: 27.6026, loss: 25.8139 ||:  86%|########5 | 855/998 [01:41<00:13, 10.45it/s]
2022-05-15 01:24:33,237 - INFO - tqdm - coref_precision: 0.7316, coref_recall: 0.5431, coref_f1: 0.6170, mention_recall: 0.9823, batch_loss: 136.4169, loss: 25.5661 ||:  95%|#########4| 948/998 [01:51<00:06,  7.71it/s]
2022-05-15 01:24:38,356 - INFO - tqdm - coref_precision: 0.7326, coref_recall: 0.5435, coref_f1: 0.6177, mention_recall: 0.9826, batch_loss: 0.0004, loss: 25.2882 ||: 100%|#########9| 994/998 [01:56<00:00,  9.03it/s]
2022-05-15 01:24:38,811 - INFO - tqdm - coref_precision: 0.7324, coref_recall: 0.5438, coref_f1: 0.6177, mention_recall: 0.9827, batch_loss: 12.0518, loss: 25.3186 ||: 100%|#########9| 996/998 [01:57<00:00,  6.86it/s]
2022-05-15 01:24:38,981 - INFO - tqdm - coref_precision: 0.7327, coref_recall: 0.5446, coref_f1: 0.6183, mention_recall: 0.9827, batch_loss: 52.8500, loss: 25.3462 ||: 100%|#########9| 997/998 [01:57<00:00,  6.66it/s]
2022-05-15 01:24:39,220 - INFO - tqdm - coref_precision: 0.7326, coref_recall: 0.5448, coref_f1: 0.6184, mention_recall: 0.9828, batch_loss: 54.8761, loss: 25.3758 ||: 100%|##########| 998/998 [01:57<00:00,  5.95it/s]
2022-05-15 01:24:39,221 - INFO - tqdm - coref_precision: 0.7326, coref_recall: 0.5448, coref_f1: 0.6184, mention_recall: 0.9828, batch_loss: 54.8761, loss: 25.3758 ||: 100%|##########| 998/998 [01:57<00:00,  8.47it/s]
2022-05-15 01:24:40,167 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:24:40,168 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:24:46,802 - INFO - tqdm - coref_precision: 0.6415, coref_recall: 0.5046, coref_f1: 0.5578, mention_recall: 0.9898, batch_loss: 393.3758, loss: 44.2389 ||: 100%|##########| 122/122 [00:06<00:00, 18.39it/s]
2022-05-15 01:24:48,682 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:24:54,718 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:24:54,718 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.618  |     0.558
2022-05-15 01:24:54,718 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.733  |     0.641
2022-05-15 01:24:54,719 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.545  |     0.505
2022-05-15 01:24:54,719 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.025  |       N/A
2022-05-15 01:24:54,719 - INFO - allennlp.training.callbacks.console_logger - loss               |    25.376  |    44.239
2022-05-15 01:24:54,719 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.983  |     0.990
2022-05-15 01:24:54,719 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7597.219  |       N/A
2022-05-15 01:24:54,719 - INFO - allennlp.training.trainer - Epoch duration: 0:02:13.323052
2022-05-15 01:24:54,719 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:25:11
2022-05-15 01:24:54,719 - INFO - allennlp.training.trainer - Epoch 4/149
2022-05-15 01:24:54,719 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:24:54,719 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:24:54,720 - INFO - allennlp.training.trainer - Training
2022-05-15 01:24:54,720 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:25:05,414 - INFO - tqdm - coref_precision: 0.7235, coref_recall: 0.5532, coref_f1: 0.6253, mention_recall: 0.9933, batch_loss: 0.0000, loss: 24.8613 ||:   9%|8         | 88/998 [00:10<03:55,  3.87it/s]
2022-05-15 01:25:15,522 - INFO - tqdm - coref_precision: 0.7539, coref_recall: 0.5760, coref_f1: 0.6493, mention_recall: 0.9926, batch_loss: 11.8207, loss: 21.2887 ||:  17%|#7        | 174/998 [00:20<02:10,  6.29it/s]
2022-05-15 01:25:25,682 - INFO - tqdm - coref_precision: 0.7710, coref_recall: 0.5864, coref_f1: 0.6607, mention_recall: 0.9919, batch_loss: 68.1779, loss: 18.1600 ||:  27%|##7       | 274/998 [00:30<01:12, 10.02it/s]
2022-05-15 01:25:35,704 - INFO - tqdm - coref_precision: 0.7686, coref_recall: 0.5785, coref_f1: 0.6550, mention_recall: 0.9925, batch_loss: 15.4685, loss: 18.7215 ||:  35%|###5      | 351/998 [00:40<01:09,  9.28it/s]
2022-05-15 01:25:45,822 - INFO - tqdm - coref_precision: 0.7711, coref_recall: 0.5713, coref_f1: 0.6515, mention_recall: 0.9911, batch_loss: 0.0000, loss: 20.7206 ||:  44%|####3     | 438/998 [00:51<00:47, 11.81it/s]
2022-05-15 01:25:55,969 - INFO - tqdm - coref_precision: 0.7750, coref_recall: 0.5752, coref_f1: 0.6544, mention_recall: 0.9915, batch_loss: 31.3495, loss: 20.2654 ||:  53%|#####2    | 528/998 [01:01<00:49,  9.46it/s]
2022-05-15 01:26:06,064 - INFO - tqdm - coref_precision: 0.7785, coref_recall: 0.5747, coref_f1: 0.6552, mention_recall: 0.9910, batch_loss: 0.0587, loss: 20.4024 ||:  61%|######    | 607/998 [01:11<00:55,  7.03it/s]
2022-05-15 01:26:16,241 - INFO - tqdm - coref_precision: 0.7785, coref_recall: 0.5787, coref_f1: 0.6581, mention_recall: 0.9910, batch_loss: 35.3347, loss: 20.3605 ||:  69%|######9   | 693/998 [01:21<00:33,  8.97it/s]
2022-05-15 01:26:27,637 - INFO - tqdm - coref_precision: 0.7659, coref_recall: 0.5735, coref_f1: 0.6500, mention_recall: 0.9901, batch_loss: 452.8506, loss: 22.3245 ||:  78%|#######7  | 774/998 [01:32<01:25,  2.62it/s]
2022-05-15 01:26:37,646 - INFO - tqdm - coref_precision: 0.7708, coref_recall: 0.5767, coref_f1: 0.6537, mention_recall: 0.9884, batch_loss: 3.6303, loss: 21.9159 ||:  85%|########5 | 852/998 [01:42<00:19,  7.67it/s]
2022-05-15 01:26:47,755 - INFO - tqdm - coref_precision: 0.7724, coref_recall: 0.5797, coref_f1: 0.6562, mention_recall: 0.9885, batch_loss: 0.0001, loss: 21.5782 ||:  95%|#########5| 950/998 [01:53<00:05,  8.68it/s]
2022-05-15 01:26:52,219 - INFO - tqdm - coref_precision: 0.7730, coref_recall: 0.5800, coref_f1: 0.6566, mention_recall: 0.9885, batch_loss: 1.0220, loss: 21.2103 ||: 100%|#########9| 995/998 [01:57<00:00, 11.64it/s]
2022-05-15 01:26:52,464 - INFO - tqdm - coref_precision: 0.7733, coref_recall: 0.5803, coref_f1: 0.6570, mention_recall: 0.9886, batch_loss: 17.0734, loss: 21.1991 ||: 100%|#########9| 997/998 [01:57<00:00, 10.26it/s]
2022-05-15 01:26:52,561 - INFO - tqdm - coref_precision: 0.7737, coref_recall: 0.5808, coref_f1: 0.6574, mention_recall: 0.9886, batch_loss: 13.8932, loss: 21.1917 ||: 100%|##########| 998/998 [01:57<00:00,  8.47it/s]
2022-05-15 01:26:53,506 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:26:53,508 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:27:00,167 - INFO - tqdm - coref_precision: 0.6508, coref_recall: 0.4860, coref_f1: 0.5466, mention_recall: 0.9909, batch_loss: 6.5120, loss: 48.4339 ||: 100%|##########| 122/122 [00:06<00:00, 18.32it/s]
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.657  |     0.547
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.774  |     0.651
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.581  |     0.486
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.025  |       N/A
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - loss               |    21.192  |    48.434
2022-05-15 01:27:02,235 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.991
2022-05-15 01:27:02,236 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7597.469  |       N/A
2022-05-15 01:27:02,236 - INFO - allennlp.training.trainer - Epoch duration: 0:02:07.517318
2022-05-15 01:27:02,236 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:19:59
2022-05-15 01:27:02,236 - INFO - allennlp.training.trainer - Epoch 5/149
2022-05-15 01:27:02,237 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:27:02,237 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:27:02,238 - INFO - allennlp.training.trainer - Training
2022-05-15 01:27:02,238 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:27:12,304 - INFO - tqdm - coref_precision: 0.7815, coref_recall: 0.5893, coref_f1: 0.6686, mention_recall: 0.9920, batch_loss: 0.2495, loss: 14.0285 ||:  10%|9         | 95/998 [00:10<01:42,  8.83it/s]
2022-05-15 01:27:22,715 - INFO - tqdm - coref_precision: 0.7889, coref_recall: 0.6014, coref_f1: 0.6769, mention_recall: 0.9906, batch_loss: 104.5528, loss: 17.1385 ||:  18%|#7        | 175/998 [00:20<02:44,  5.00it/s]
2022-05-15 01:27:33,601 - INFO - tqdm - coref_precision: 0.7794, coref_recall: 0.6092, coref_f1: 0.6767, mention_recall: 0.9923, batch_loss: 197.2604, loss: 18.8396 ||:  25%|##5       | 254/998 [00:31<03:24,  3.63it/s]
2022-05-15 01:27:43,702 - INFO - tqdm - coref_precision: 0.7837, coref_recall: 0.6173, coref_f1: 0.6834, mention_recall: 0.9923, batch_loss: 3.6187, loss: 17.7819 ||:  34%|###4      | 344/998 [00:41<01:04, 10.18it/s]
2022-05-15 01:27:53,830 - INFO - tqdm - coref_precision: 0.7849, coref_recall: 0.6201, coref_f1: 0.6858, mention_recall: 0.9925, batch_loss: 0.0015, loss: 17.8468 ||:  44%|####4     | 441/998 [00:51<00:48, 11.59it/s]
2022-05-15 01:28:03,883 - INFO - tqdm - coref_precision: 0.7817, coref_recall: 0.6146, coref_f1: 0.6810, mention_recall: 0.9883, batch_loss: 0.0000, loss: 18.5366 ||:  52%|#####1    | 518/998 [01:01<00:49,  9.79it/s]
2022-05-15 01:28:13,933 - INFO - tqdm - coref_precision: 0.7884, coref_recall: 0.6178, coref_f1: 0.6854, mention_recall: 0.9891, batch_loss: 4.3649, loss: 17.8052 ||:  60%|######    | 600/998 [01:11<00:44,  8.89it/s]
2022-05-15 01:28:23,977 - INFO - tqdm - coref_precision: 0.7952, coref_recall: 0.6236, coref_f1: 0.6917, mention_recall: 0.9890, batch_loss: 3.9933, loss: 17.8436 ||:  69%|######8   | 686/998 [01:21<00:30, 10.31it/s]
2022-05-15 01:28:34,023 - INFO - tqdm - coref_precision: 0.7879, coref_recall: 0.6204, coref_f1: 0.6864, mention_recall: 0.9884, batch_loss: 0.0004, loss: 19.3045 ||:  78%|#######7  | 774/998 [01:31<00:46,  4.81it/s]
2022-05-15 01:28:44,039 - INFO - tqdm - coref_precision: 0.7923, coref_recall: 0.6229, coref_f1: 0.6894, mention_recall: 0.9889, batch_loss: 0.0255, loss: 18.8159 ||:  87%|########6 | 868/998 [01:41<00:13,  9.54it/s]
2022-05-15 01:28:54,075 - INFO - tqdm - coref_precision: 0.7967, coref_recall: 0.6270, coref_f1: 0.6935, mention_recall: 0.9893, batch_loss: 8.2126, loss: 18.3013 ||:  95%|#########5| 951/998 [01:51<00:05,  9.32it/s]
2022-05-15 01:28:59,144 - INFO - tqdm - coref_precision: 0.7970, coref_recall: 0.6181, coref_f1: 0.6883, mention_recall: 0.9893, batch_loss: 0.0003, loss: 19.0098 ||: 100%|#########9| 995/998 [01:56<00:00,  8.98it/s]
2022-05-15 01:28:59,578 - INFO - tqdm - coref_precision: 0.7964, coref_recall: 0.6186, coref_f1: 0.6884, mention_recall: 0.9894, batch_loss: 0.2385, loss: 19.0094 ||: 100%|#########9| 997/998 [01:57<00:00,  6.97it/s]
2022-05-15 01:28:59,754 - INFO - tqdm - coref_precision: 0.7964, coref_recall: 0.6188, coref_f1: 0.6886, mention_recall: 0.9894, batch_loss: 16.5978, loss: 19.0070 ||: 100%|##########| 998/998 [01:57<00:00,  6.70it/s]
2022-05-15 01:28:59,755 - INFO - tqdm - coref_precision: 0.7964, coref_recall: 0.6188, coref_f1: 0.6886, mention_recall: 0.9894, batch_loss: 16.5978, loss: 19.0070 ||: 100%|##########| 998/998 [01:57<00:00,  8.49it/s]
2022-05-15 01:29:00,704 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:29:00,706 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:29:07,324 - INFO - tqdm - coref_precision: 0.6538, coref_recall: 0.4927, coref_f1: 0.5548, mention_recall: 0.9848, batch_loss: 7.1146, loss: 46.8224 ||: 100%|##########| 122/122 [00:06<00:00, 18.43it/s]
2022-05-15 01:29:09,397 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:29:09,397 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.689  |     0.555
2022-05-15 01:29:09,397 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.796  |     0.654
2022-05-15 01:29:09,398 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.619  |     0.493
2022-05-15 01:29:09,398 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.025  |       N/A
2022-05-15 01:29:09,398 - INFO - allennlp.training.callbacks.console_logger - loss               |    19.007  |    46.822
2022-05-15 01:29:09,398 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.985
2022-05-15 01:29:09,398 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7598.219  |       N/A
2022-05-15 01:29:09,398 - INFO - allennlp.training.trainer - Epoch duration: 0:02:07.161433
2022-05-15 01:29:09,398 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:15:41
2022-05-15 01:29:09,398 - INFO - allennlp.training.trainer - Epoch 6/149
2022-05-15 01:29:09,398 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:29:09,398 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:29:09,399 - INFO - allennlp.training.trainer - Training
2022-05-15 01:29:09,400 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:29:19,805 - INFO - tqdm - coref_precision: 0.8548, coref_recall: 0.6702, coref_f1: 0.7398, mention_recall: 0.9900, batch_loss: 4.1203, loss: 9.0670 ||:  10%|9         | 99/998 [00:10<02:00,  7.43it/s]
2022-05-15 01:29:29,910 - INFO - tqdm - coref_precision: 0.8052, coref_recall: 0.6034, coref_f1: 0.6818, mention_recall: 0.9926, batch_loss: 28.7203, loss: 19.8939 ||:  18%|#7        | 178/998 [00:20<01:34,  8.71it/s]
2022-05-15 01:29:40,090 - INFO - tqdm - coref_precision: 0.8097, coref_recall: 0.5879, coref_f1: 0.6741, mention_recall: 0.9918, batch_loss: 4.0013, loss: 21.2136 ||:  27%|##6       | 269/998 [00:30<01:20,  9.04it/s]
2022-05-15 01:29:50,193 - INFO - tqdm - coref_precision: 0.8176, coref_recall: 0.6054, coref_f1: 0.6882, mention_recall: 0.9909, batch_loss: 31.7081, loss: 19.4574 ||:  36%|###5      | 357/998 [00:40<01:31,  6.97it/s]
2022-05-15 01:30:00,335 - INFO - tqdm - coref_precision: 0.8160, coref_recall: 0.6105, coref_f1: 0.6907, mention_recall: 0.9918, batch_loss: 98.5511, loss: 19.5316 ||:  43%|####3     | 432/998 [00:50<01:24,  6.70it/s]
2022-05-15 01:30:10,455 - INFO - tqdm - coref_precision: 0.8192, coref_recall: 0.6155, coref_f1: 0.6951, mention_recall: 0.9921, batch_loss: 0.0002, loss: 19.6647 ||:  51%|#####1    | 512/998 [01:01<01:04,  7.57it/s]
2022-05-15 01:30:21,273 - INFO - tqdm - coref_precision: 0.8124, coref_recall: 0.6196, coref_f1: 0.6954, mention_recall: 0.9926, batch_loss: 557.8612, loss: 19.7868 ||:  60%|#####9    | 597/998 [01:11<01:52,  3.55it/s]
2022-05-15 01:30:31,412 - INFO - tqdm - coref_precision: 0.8177, coref_recall: 0.6257, coref_f1: 0.7011, mention_recall: 0.9926, batch_loss: 0.0000, loss: 17.8254 ||:  71%|#######   | 708/998 [01:22<00:24, 11.88it/s]
2022-05-15 01:30:41,453 - INFO - tqdm - coref_precision: 0.8162, coref_recall: 0.6279, coref_f1: 0.7020, mention_recall: 0.9932, batch_loss: 56.2229, loss: 17.7113 ||:  79%|#######9  | 790/998 [01:32<00:37,  5.52it/s]
2022-05-15 01:30:51,545 - INFO - tqdm - coref_precision: 0.8117, coref_recall: 0.6300, coref_f1: 0.7015, mention_recall: 0.9930, batch_loss: 0.0006, loss: 17.9577 ||:  87%|########7 | 871/998 [01:42<00:11, 10.62it/s]
2022-05-15 01:31:01,659 - INFO - tqdm - coref_precision: 0.8115, coref_recall: 0.6313, coref_f1: 0.7023, mention_recall: 0.9930, batch_loss: 4.6965, loss: 17.5607 ||:  96%|#########5| 954/998 [01:52<00:04, 10.90it/s]
2022-05-15 01:31:06,347 - INFO - tqdm - coref_precision: 0.8128, coref_recall: 0.6342, coref_f1: 0.7046, mention_recall: 0.9930, batch_loss: 1.5126, loss: 17.3136 ||: 100%|#########9| 995/998 [01:56<00:00,  8.10it/s]
2022-05-15 01:31:06,482 - INFO - tqdm - coref_precision: 0.8129, coref_recall: 0.6343, coref_f1: 0.7046, mention_recall: 0.9930, batch_loss: 0.0000, loss: 17.2789 ||: 100%|#########9| 997/998 [01:57<00:00,  9.68it/s]
2022-05-15 01:31:06,770 - INFO - tqdm - coref_precision: 0.8128, coref_recall: 0.6345, coref_f1: 0.7047, mention_recall: 0.9931, batch_loss: 45.7751, loss: 17.3075 ||: 100%|##########| 998/998 [01:57<00:00,  8.50it/s]
2022-05-15 01:31:07,722 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:31:07,723 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:31:14,437 - INFO - tqdm - coref_precision: 0.6128, coref_recall: 0.5315, coref_f1: 0.5629, mention_recall: 0.9870, batch_loss: 109.7536, loss: 50.1534 ||: 100%|##########| 122/122 [00:06<00:00, 19.68it/s]
2022-05-15 01:31:14,437 - INFO - tqdm - coref_precision: 0.6128, coref_recall: 0.5315, coref_f1: 0.5629, mention_recall: 0.9870, batch_loss: 109.7536, loss: 50.1534 ||: 100%|##########| 122/122 [00:06<00:00, 18.17it/s]
2022-05-15 01:31:16,324 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:31:27,821 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.705  |     0.563
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.813  |     0.613
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.634  |     0.531
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.025  |       N/A
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - loss               |    17.307  |    50.153
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.993  |     0.987
2022-05-15 01:31:27,822 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7598.219  |       N/A
2022-05-15 01:31:27,822 - INFO - allennlp.training.trainer - Epoch duration: 0:02:18.424109
2022-05-15 01:31:27,822 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:15:50
2022-05-15 01:31:27,822 - INFO - allennlp.training.trainer - Epoch 7/149
2022-05-15 01:31:27,822 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:31:27,823 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:31:27,824 - INFO - allennlp.training.trainer - Training
2022-05-15 01:31:27,824 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:31:37,958 - INFO - tqdm - coref_precision: 0.8461, coref_recall: 0.6712, coref_f1: 0.7430, mention_recall: 0.9915, batch_loss: 0.0336, loss: 12.3895 ||:   9%|9         | 90/998 [00:10<01:19, 11.43it/s]
2022-05-15 01:31:48,109 - INFO - tqdm - coref_precision: 0.8484, coref_recall: 0.6704, coref_f1: 0.7411, mention_recall: 0.9911, batch_loss: 30.6376, loss: 11.2314 ||:  19%|#9        | 190/998 [00:20<01:53,  7.15it/s]
2022-05-15 01:31:58,178 - INFO - tqdm - coref_precision: 0.8396, coref_recall: 0.6769, coref_f1: 0.7410, mention_recall: 0.9919, batch_loss: 34.4782, loss: 11.6659 ||:  27%|##7       | 272/998 [00:30<01:09, 10.51it/s]
2022-05-15 01:32:08,292 - INFO - tqdm - coref_precision: 0.8451, coref_recall: 0.6759, coref_f1: 0.7422, mention_recall: 0.9919, batch_loss: 0.0000, loss: 11.1421 ||:  36%|###6      | 363/998 [00:40<00:50, 12.59it/s]
2022-05-15 01:32:18,427 - INFO - tqdm - coref_precision: 0.8364, coref_recall: 0.6817, coref_f1: 0.7408, mention_recall: 0.9918, batch_loss: 14.8779, loss: 14.2408 ||:  44%|####4     | 442/998 [00:50<01:24,  6.58it/s]
2022-05-15 01:32:28,457 - INFO - tqdm - coref_precision: 0.8399, coref_recall: 0.6835, coref_f1: 0.7435, mention_recall: 0.9913, batch_loss: 0.1400, loss: 13.3738 ||:  53%|#####3    | 533/998 [01:00<00:39, 11.80it/s]
2022-05-15 01:32:38,584 - INFO - tqdm - coref_precision: 0.8340, coref_recall: 0.6775, coref_f1: 0.7377, mention_recall: 0.9919, batch_loss: 0.0004, loss: 13.7669 ||:  62%|######2   | 619/998 [01:10<00:57,  6.57it/s]
2022-05-15 01:32:48,748 - INFO - tqdm - coref_precision: 0.8329, coref_recall: 0.6762, coref_f1: 0.7369, mention_recall: 0.9920, batch_loss: 0.0016, loss: 13.6808 ||:  71%|#######   | 705/998 [01:20<00:36,  8.07it/s]
2022-05-15 01:32:58,921 - INFO - tqdm - coref_precision: 0.8260, coref_recall: 0.6722, coref_f1: 0.7324, mention_recall: 0.9924, batch_loss: 36.6889, loss: 14.6654 ||:  79%|#######8  | 784/998 [01:31<01:07,  3.16it/s]
2022-05-15 01:33:08,938 - INFO - tqdm - coref_precision: 0.8275, coref_recall: 0.6726, coref_f1: 0.7334, mention_recall: 0.9918, batch_loss: 16.8022, loss: 14.9420 ||:  86%|########5 | 858/998 [01:41<00:14,  9.64it/s]
2022-05-15 01:33:18,987 - INFO - tqdm - coref_precision: 0.8290, coref_recall: 0.6682, coref_f1: 0.7318, mention_recall: 0.9918, batch_loss: 0.0002, loss: 15.4420 ||:  95%|#########4| 947/998 [01:51<00:04, 11.86it/s]
2022-05-15 01:33:23,895 - INFO - tqdm - coref_precision: 0.8322, coref_recall: 0.6709, coref_f1: 0.7346, mention_recall: 0.9919, batch_loss: 0.0000, loss: 15.1363 ||: 100%|#########9| 994/998 [01:56<00:00, 12.18it/s]
2022-05-15 01:33:24,125 - INFO - tqdm - coref_precision: 0.8321, coref_recall: 0.6711, coref_f1: 0.7347, mention_recall: 0.9920, batch_loss: 25.8232, loss: 15.1360 ||: 100%|#########9| 996/998 [01:56<00:00, 10.87it/s]
2022-05-15 01:33:24,288 - INFO - tqdm - coref_precision: 0.8321, coref_recall: 0.6712, coref_f1: 0.7348, mention_recall: 0.9920, batch_loss: 5.6690, loss: 15.1114 ||: 100%|##########| 998/998 [01:56<00:00, 11.27it/s]
2022-05-15 01:33:24,288 - INFO - tqdm - coref_precision: 0.8321, coref_recall: 0.6712, coref_f1: 0.7348, mention_recall: 0.9920, batch_loss: 5.6690, loss: 15.1114 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:33:25,229 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:33:25,231 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:33:32,683 - INFO - tqdm - coref_precision: 0.6559, coref_recall: 0.4901, coref_f1: 0.5549, mention_recall: 0.9859, batch_loss: 57.4371, loss: 49.1971 ||: 100%|##########| 122/122 [00:07<00:00, 16.37it/s]
2022-05-15 01:33:34,765 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.735  |     0.555
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.832  |     0.656
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.671  |     0.490
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - loss               |    15.111  |    49.197
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.992  |     0.986
2022-05-15 01:33:34,766 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7598.219  |       N/A
2022-05-15 01:33:34,766 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.943946
2022-05-15 01:33:34,766 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:11:59
2022-05-15 01:33:34,766 - INFO - allennlp.training.trainer - Epoch 8/149
2022-05-15 01:33:34,767 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:33:34,767 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:33:34,768 - INFO - allennlp.training.trainer - Training
2022-05-15 01:33:34,768 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:33:45,108 - INFO - tqdm - coref_precision: 0.7861, coref_recall: 0.6711, coref_f1: 0.7141, mention_recall: 0.9904, batch_loss: 206.3156, loss: 18.1503 ||:   9%|8         | 88/998 [00:10<03:42,  4.09it/s]
2022-05-15 01:33:55,244 - INFO - tqdm - coref_precision: 0.8445, coref_recall: 0.7076, coref_f1: 0.7580, mention_recall: 0.9899, batch_loss: 2.2175, loss: 11.5429 ||:  19%|#8        | 187/998 [00:20<01:20, 10.05it/s]
2022-05-15 01:34:05,598 - INFO - tqdm - coref_precision: 0.8426, coref_recall: 0.6709, coref_f1: 0.7376, mention_recall: 0.9916, batch_loss: 0.3656, loss: 14.9134 ||:  27%|##7       | 271/998 [00:30<01:30,  7.99it/s]
2022-05-15 01:34:15,720 - INFO - tqdm - coref_precision: 0.8330, coref_recall: 0.6623, coref_f1: 0.7299, mention_recall: 0.9913, batch_loss: 63.9066, loss: 15.0971 ||:  35%|###5      | 354/998 [00:40<01:06,  9.75it/s]
2022-05-15 01:34:25,768 - INFO - tqdm - coref_precision: 0.8363, coref_recall: 0.6710, coref_f1: 0.7361, mention_recall: 0.9910, batch_loss: 0.1937, loss: 14.5868 ||:  43%|####2     | 429/998 [00:50<00:51, 11.09it/s]
2022-05-15 01:34:35,895 - INFO - tqdm - coref_precision: 0.8375, coref_recall: 0.6757, coref_f1: 0.7396, mention_recall: 0.9914, batch_loss: 1.0833, loss: 14.4366 ||:  51%|#####1    | 509/998 [01:01<00:54,  8.95it/s]
2022-05-15 01:34:45,951 - INFO - tqdm - coref_precision: 0.8408, coref_recall: 0.6771, coref_f1: 0.7412, mention_recall: 0.9910, batch_loss: 0.0004, loss: 13.6853 ||:  61%|######    | 604/998 [01:11<00:33, 11.76it/s]
2022-05-15 01:34:56,944 - INFO - tqdm - coref_precision: 0.8381, coref_recall: 0.6743, coref_f1: 0.7391, mention_recall: 0.9908, batch_loss: 207.7441, loss: 13.8671 ||:  69%|######9   | 691/998 [01:22<01:28,  3.49it/s]
2022-05-15 01:35:07,096 - INFO - tqdm - coref_precision: 0.8417, coref_recall: 0.6791, coref_f1: 0.7434, mention_recall: 0.9912, batch_loss: 0.0001, loss: 13.2629 ||:  79%|#######8  | 784/998 [01:32<00:16, 12.72it/s]
2022-05-15 01:35:17,173 - INFO - tqdm - coref_precision: 0.8419, coref_recall: 0.6797, coref_f1: 0.7436, mention_recall: 0.9911, batch_loss: 0.0040, loss: 13.0098 ||:  87%|########7 | 872/998 [01:42<00:11, 11.23it/s]
2022-05-15 01:35:27,252 - INFO - tqdm - coref_precision: 0.8423, coref_recall: 0.6739, coref_f1: 0.7408, mention_recall: 0.9913, batch_loss: 0.0001, loss: 13.9106 ||:  96%|#########6| 961/998 [01:52<00:03,  9.67it/s]
2022-05-15 01:35:30,683 - INFO - tqdm - coref_precision: 0.8432, coref_recall: 0.6761, coref_f1: 0.7425, mention_recall: 0.9913, batch_loss: 1.3700, loss: 13.9197 ||: 100%|#########9| 995/998 [01:55<00:00,  9.02it/s]
2022-05-15 01:35:30,844 - INFO - tqdm - coref_precision: 0.8434, coref_recall: 0.6765, coref_f1: 0.7428, mention_recall: 0.9913, batch_loss: 0.0000, loss: 13.9042 ||: 100%|#########9| 997/998 [01:56<00:00,  9.84it/s]
2022-05-15 01:35:31,016 - INFO - tqdm - coref_precision: 0.8435, coref_recall: 0.6767, coref_f1: 0.7430, mention_recall: 0.9913, batch_loss: 14.2009, loss: 13.9045 ||: 100%|##########| 998/998 [01:56<00:00,  8.59it/s]
2022-05-15 01:35:31,950 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:35:31,951 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:35:39,362 - INFO - tqdm - coref_precision: 0.6596, coref_recall: 0.4929, coref_f1: 0.5580, mention_recall: 0.9796, batch_loss: 52.5475, loss: 53.3686 ||: 100%|##########| 122/122 [00:07<00:00, 16.46it/s]
2022-05-15 01:35:41,442 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:35:41,442 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.743  |     0.558
2022-05-15 01:35:41,442 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.844  |     0.660
2022-05-15 01:35:41,442 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.677  |     0.493
2022-05-15 01:35:41,443 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:35:41,443 - INFO - allennlp.training.callbacks.console_logger - loss               |    13.904  |    53.369
2022-05-15 01:35:41,443 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.991  |     0.980
2022-05-15 01:35:41,443 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7598.469  |       N/A
2022-05-15 01:35:41,443 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.676384
2022-05-15 01:35:41,443 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:08:26
2022-05-15 01:35:41,443 - INFO - allennlp.training.trainer - Epoch 9/149
2022-05-15 01:35:41,443 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:35:41,443 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:35:41,444 - INFO - allennlp.training.trainer - Training
2022-05-15 01:35:41,444 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:35:51,569 - INFO - tqdm - coref_precision: 0.8006, coref_recall: 0.5479, coref_f1: 0.6494, mention_recall: 0.9959, batch_loss: 0.0002, loss: 45.2309 ||:   7%|6         | 69/998 [00:10<02:50,  5.46it/s]
2022-05-15 01:36:01,626 - INFO - tqdm - coref_precision: 0.8252, coref_recall: 0.5977, coref_f1: 0.6897, mention_recall: 0.9936, batch_loss: 0.0000, loss: 27.7148 ||:  15%|#4        | 148/998 [00:20<01:31,  9.27it/s]
2022-05-15 01:36:11,941 - INFO - tqdm - coref_precision: 0.8419, coref_recall: 0.6297, coref_f1: 0.7160, mention_recall: 0.9929, batch_loss: 8.2101, loss: 20.8133 ||:  24%|##3       | 238/998 [00:30<01:18,  9.65it/s]
2022-05-15 01:36:22,007 - INFO - tqdm - coref_precision: 0.8559, coref_recall: 0.6514, coref_f1: 0.7338, mention_recall: 0.9910, batch_loss: 0.0000, loss: 17.5845 ||:  32%|###2      | 324/998 [00:40<00:58, 11.49it/s]
2022-05-15 01:36:32,319 - INFO - tqdm - coref_precision: 0.8667, coref_recall: 0.6643, coref_f1: 0.7456, mention_recall: 0.9900, batch_loss: 0.0000, loss: 15.2137 ||:  42%|####2     | 424/998 [00:50<01:24,  6.77it/s]
2022-05-15 01:36:42,385 - INFO - tqdm - coref_precision: 0.8638, coref_recall: 0.6718, coref_f1: 0.7492, mention_recall: 0.9898, batch_loss: 67.3484, loss: 14.5464 ||:  51%|#####     | 507/998 [01:00<01:02,  7.86it/s]
2022-05-15 01:36:52,750 - INFO - tqdm - coref_precision: 0.8662, coref_recall: 0.6796, coref_f1: 0.7548, mention_recall: 0.9901, batch_loss: 10.9194, loss: 13.9434 ||:  59%|#####9    | 593/998 [01:11<00:53,  7.61it/s]
2022-05-15 01:37:02,828 - INFO - tqdm - coref_precision: 0.8685, coref_recall: 0.6835, coref_f1: 0.7579, mention_recall: 0.9901, batch_loss: 0.0000, loss: 12.9893 ||:  69%|######9   | 693/998 [01:21<00:32,  9.39it/s]
2022-05-15 01:37:13,118 - INFO - tqdm - coref_precision: 0.8699, coref_recall: 0.6877, coref_f1: 0.7609, mention_recall: 0.9895, batch_loss: 0.0000, loss: 12.4510 ||:  79%|#######8  | 785/998 [01:31<00:23,  8.88it/s]
2022-05-15 01:37:23,130 - INFO - tqdm - coref_precision: 0.8571, coref_recall: 0.6859, coref_f1: 0.7548, mention_recall: 0.9897, batch_loss: 3.5775, loss: 13.3091 ||:  86%|########5 | 858/998 [01:41<00:21,  6.39it/s]
2022-05-15 01:37:33,242 - INFO - tqdm - coref_precision: 0.8595, coref_recall: 0.6890, coref_f1: 0.7574, mention_recall: 0.9894, batch_loss: 50.3996, loss: 12.6877 ||:  96%|#########5| 955/998 [01:51<00:04,  8.91it/s]
2022-05-15 01:37:37,401 - INFO - tqdm - coref_precision: 0.8599, coref_recall: 0.6890, coref_f1: 0.7574, mention_recall: 0.9896, batch_loss: 73.2659, loss: 12.6574 ||: 100%|#########9| 994/998 [01:55<00:00, 10.43it/s]
2022-05-15 01:37:37,689 - INFO - tqdm - coref_precision: 0.8600, coref_recall: 0.6887, coref_f1: 0.7572, mention_recall: 0.9895, batch_loss: 10.2199, loss: 12.7200 ||: 100%|#########9| 996/998 [01:56<00:00,  9.06it/s]
2022-05-15 01:37:37,858 - INFO - tqdm - coref_precision: 0.8601, coref_recall: 0.6886, coref_f1: 0.7572, mention_recall: 0.9895, batch_loss: 3.6191, loss: 12.7108 ||: 100%|#########9| 997/998 [01:56<00:00,  8.28it/s]
2022-05-15 01:37:37,940 - INFO - tqdm - coref_precision: 0.8601, coref_recall: 0.6886, coref_f1: 0.7572, mention_recall: 0.9895, batch_loss: 18.8105, loss: 12.7169 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:37:38,891 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:37:38,893 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:37:46,384 - INFO - tqdm - coref_precision: 0.6320, coref_recall: 0.5074, coref_f1: 0.5556, mention_recall: 0.9744, batch_loss: 42.7808, loss: 69.3808 ||: 100%|##########| 122/122 [00:07<00:00, 16.29it/s]
2022-05-15 01:37:48,471 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.757  |     0.556
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.860  |     0.632
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.689  |     0.507
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - loss               |    12.717  |    69.381
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.990  |     0.974
2022-05-15 01:37:48,472 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7598.719  |       N/A
2022-05-15 01:37:48,472 - INFO - allennlp.training.trainer - Epoch duration: 0:02:07.029132
2022-05-15 01:37:48,472 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:05:16
2022-05-15 01:37:48,472 - INFO - allennlp.training.trainer - Epoch 10/149
2022-05-15 01:37:48,472 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:37:48,473 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:37:48,474 - INFO - allennlp.training.trainer - Training
2022-05-15 01:37:48,474 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:37:58,665 - INFO - tqdm - coref_precision: 0.8400, coref_recall: 0.6778, coref_f1: 0.7424, mention_recall: 0.9902, batch_loss: 16.5102, loss: 18.9958 ||:   8%|8         | 83/998 [00:10<02:11,  6.97it/s]
2022-05-15 01:38:08,831 - INFO - tqdm - coref_precision: 0.8521, coref_recall: 0.6971, coref_f1: 0.7598, mention_recall: 0.9886, batch_loss: 3.7858, loss: 13.6158 ||:  18%|#7        | 179/998 [00:20<02:03,  6.65it/s]
2022-05-15 01:38:18,885 - INFO - tqdm - coref_precision: 0.8683, coref_recall: 0.7039, coref_f1: 0.7691, mention_recall: 0.9875, batch_loss: 0.0000, loss: 11.5132 ||:  27%|##6       | 269/998 [00:30<01:04, 11.31it/s]
2022-05-15 01:38:29,016 - INFO - tqdm - coref_precision: 0.8715, coref_recall: 0.7103, coref_f1: 0.7747, mention_recall: 0.9892, batch_loss: 0.0000, loss: 10.5058 ||:  37%|###6      | 367/998 [00:40<00:56, 11.11it/s]
2022-05-15 01:38:39,211 - INFO - tqdm - coref_precision: 0.8780, coref_recall: 0.7189, coref_f1: 0.7816, mention_recall: 0.9870, batch_loss: 59.1097, loss: 10.1420 ||:  45%|####5     | 454/998 [00:50<00:53, 10.26it/s]
2022-05-15 01:38:49,359 - INFO - tqdm - coref_precision: 0.8826, coref_recall: 0.7234, coref_f1: 0.7863, mention_recall: 0.9872, batch_loss: 0.3911, loss: 9.8409 ||:  54%|#####4    | 542/998 [01:00<00:54,  8.44it/s]
2022-05-15 01:38:59,414 - INFO - tqdm - coref_precision: 0.8858, coref_recall: 0.7123, coref_f1: 0.7815, mention_recall: 0.9876, batch_loss: 0.0000, loss: 10.5981 ||:  63%|######3   | 631/998 [01:10<00:30, 12.08it/s]
2022-05-15 01:39:09,420 - INFO - tqdm - coref_precision: 0.8901, coref_recall: 0.7166, coref_f1: 0.7858, mention_recall: 0.9870, batch_loss: 0.0000, loss: 9.6993 ||:  73%|#######2  | 726/998 [01:20<00:25, 10.78it/s]
2022-05-15 01:39:19,560 - INFO - tqdm - coref_precision: 0.8771, coref_recall: 0.7077, coref_f1: 0.7757, mention_recall: 0.9872, batch_loss: 4.4977, loss: 10.4287 ||:  79%|#######9  | 789/998 [01:31<00:35,  5.94it/s]
2022-05-15 01:39:29,590 - INFO - tqdm - coref_precision: 0.8789, coref_recall: 0.7093, coref_f1: 0.7771, mention_recall: 0.9868, batch_loss: 200.6802, loss: 10.3044 ||:  89%|########8 | 886/998 [01:41<00:16,  6.75it/s]
2022-05-15 01:39:39,727 - INFO - tqdm - coref_precision: 0.8806, coref_recall: 0.7127, coref_f1: 0.7800, mention_recall: 0.9870, batch_loss: 1.1833, loss: 10.0834 ||:  97%|#########6| 968/998 [01:51<00:05,  5.60it/s]
2022-05-15 01:39:43,335 - INFO - tqdm - coref_precision: 0.8807, coref_recall: 0.7099, coref_f1: 0.7783, mention_recall: 0.9871, batch_loss: 182.7235, loss: 10.3677 ||: 100%|#########9| 994/998 [01:54<00:00,  5.48it/s]
2022-05-15 01:39:43,436 - INFO - tqdm - coref_precision: 0.8808, coref_recall: 0.7100, coref_f1: 0.7783, mention_recall: 0.9872, batch_loss: 0.0214, loss: 10.3573 ||: 100%|#########9| 995/998 [01:54<00:00,  6.25it/s]
2022-05-15 01:39:44,219 - INFO - tqdm - coref_precision: 0.8800, coref_recall: 0.7089, coref_f1: 0.7776, mention_recall: 0.9872, batch_loss: 76.1763, loss: 10.4234 ||: 100%|#########9| 996/998 [01:55<00:00,  2.97it/s]
2022-05-15 01:39:44,628 - INFO - tqdm - coref_precision: 0.8801, coref_recall: 0.7091, coref_f1: 0.7777, mention_recall: 0.9873, batch_loss: 10.8810, loss: 10.4134 ||: 100%|##########| 998/998 [01:56<00:00,  3.60it/s]
2022-05-15 01:39:44,628 - INFO - tqdm - coref_precision: 0.8801, coref_recall: 0.7091, coref_f1: 0.7777, mention_recall: 0.9873, batch_loss: 10.8810, loss: 10.4134 ||: 100%|##########| 998/998 [01:56<00:00,  8.59it/s]
2022-05-15 01:39:45,571 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:39:45,572 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:39:52,197 - INFO - tqdm - coref_precision: 0.6528, coref_recall: 0.4929, coref_f1: 0.5546, mention_recall: 0.9815, batch_loss: 42.3426, loss: 56.5583 ||: 100%|##########| 122/122 [00:06<00:00, 20.46it/s]
2022-05-15 01:39:52,197 - INFO - tqdm - coref_precision: 0.6528, coref_recall: 0.4929, coref_f1: 0.5546, mention_recall: 0.9815, batch_loss: 42.3426, loss: 56.5583 ||: 100%|##########| 122/122 [00:06<00:00, 18.42it/s]
2022-05-15 01:39:54,259 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.778  |     0.555
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.880  |     0.653
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.709  |     0.493
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - loss               |    10.413  |    56.558
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.982
2022-05-15 01:39:54,260 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.219  |       N/A
2022-05-15 01:39:54,260 - INFO - allennlp.training.trainer - Epoch duration: 0:02:05.787672
2022-05-15 01:39:54,260 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:02:01
2022-05-15 01:39:54,260 - INFO - allennlp.training.trainer - Epoch 11/149
2022-05-15 01:39:54,260 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:39:54,260 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:39:54,261 - INFO - allennlp.training.trainer - Training
2022-05-15 01:39:54,262 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:40:04,454 - INFO - tqdm - coref_precision: 0.9176, coref_recall: 0.7611, coref_f1: 0.8188, mention_recall: 0.9841, batch_loss: 2.1134, loss: 4.5217 ||:   9%|8         | 88/998 [00:10<01:50,  8.23it/s]
2022-05-15 01:40:14,526 - INFO - tqdm - coref_precision: 0.9208, coref_recall: 0.7579, coref_f1: 0.8198, mention_recall: 0.9862, batch_loss: 0.1981, loss: 5.2019 ||:  19%|#8        | 186/998 [00:20<01:07, 12.10it/s]
2022-05-15 01:40:24,634 - INFO - tqdm - coref_precision: 0.8947, coref_recall: 0.7440, coref_f1: 0.8030, mention_recall: 0.9879, batch_loss: 0.9219, loss: 7.5730 ||:  26%|##6       | 264/998 [00:30<03:01,  4.05it/s]
2022-05-15 01:40:34,801 - INFO - tqdm - coref_precision: 0.8961, coref_recall: 0.7322, coref_f1: 0.7967, mention_recall: 0.9877, batch_loss: 28.1616, loss: 7.4712 ||:  35%|###5      | 351/998 [00:40<02:17,  4.72it/s]
2022-05-15 01:40:44,940 - INFO - tqdm - coref_precision: 0.8967, coref_recall: 0.7302, coref_f1: 0.7961, mention_recall: 0.9883, batch_loss: 0.0000, loss: 7.7080 ||:  43%|####3     | 433/998 [00:50<00:50, 11.24it/s]
2022-05-15 01:40:55,183 - INFO - tqdm - coref_precision: 0.8884, coref_recall: 0.7208, coref_f1: 0.7870, mention_recall: 0.9890, batch_loss: 445.7434, loss: 8.5051 ||:  51%|#####     | 508/998 [01:00<02:06,  3.88it/s]
2022-05-15 01:41:05,312 - INFO - tqdm - coref_precision: 0.8941, coref_recall: 0.7022, coref_f1: 0.7792, mention_recall: 0.9895, batch_loss: 10.3652, loss: 10.9562 ||:  59%|#####9    | 591/998 [01:11<00:41,  9.74it/s]
2022-05-15 01:41:15,498 - INFO - tqdm - coref_precision: 0.8984, coref_recall: 0.7084, coref_f1: 0.7844, mention_recall: 0.9892, batch_loss: 0.0000, loss: 10.1824 ||:  69%|######8   | 685/998 [01:21<00:35,  8.78it/s]
2022-05-15 01:41:25,570 - INFO - tqdm - coref_precision: 0.8942, coref_recall: 0.7073, coref_f1: 0.7821, mention_recall: 0.9893, batch_loss: 0.0002, loss: 10.2220 ||:  77%|#######6  | 764/998 [01:31<00:16, 13.86it/s]
2022-05-15 01:41:35,595 - INFO - tqdm - coref_precision: 0.8966, coref_recall: 0.7142, coref_f1: 0.7870, mention_recall: 0.9890, batch_loss: 15.0380, loss: 9.5238 ||:  87%|########6 | 865/998 [01:41<00:12, 10.34it/s]
2022-05-15 01:41:45,677 - INFO - tqdm - coref_precision: 0.8948, coref_recall: 0.7147, coref_f1: 0.7866, mention_recall: 0.9890, batch_loss: 8.2250, loss: 9.4532 ||:  96%|#########5| 956/998 [01:51<00:04,  8.48it/s]
2022-05-15 01:41:50,560 - INFO - tqdm - coref_precision: 0.8952, coref_recall: 0.7168, coref_f1: 0.7882, mention_recall: 0.9892, batch_loss: 0.6091, loss: 9.4084 ||: 100%|#########9| 994/998 [01:56<00:00,  8.51it/s]
2022-05-15 01:41:50,687 - INFO - tqdm - coref_precision: 0.8950, coref_recall: 0.7170, coref_f1: 0.7882, mention_recall: 0.9892, batch_loss: 32.9160, loss: 9.4321 ||: 100%|#########9| 995/998 [01:56<00:00,  8.38it/s]
2022-05-15 01:41:50,835 - INFO - tqdm - coref_precision: 0.8951, coref_recall: 0.7170, coref_f1: 0.7883, mention_recall: 0.9892, batch_loss: 0.0000, loss: 9.4132 ||: 100%|#########9| 997/998 [01:56<00:00,  9.64it/s]
2022-05-15 01:41:50,902 - INFO - tqdm - coref_precision: 0.8951, coref_recall: 0.7171, coref_f1: 0.7883, mention_recall: 0.9892, batch_loss: 0.0774, loss: 9.4038 ||: 100%|##########| 998/998 [01:56<00:00,  8.56it/s]
2022-05-15 01:41:51,840 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:41:51,841 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:41:58,443 - INFO - tqdm - coref_precision: 0.6608, coref_recall: 0.4913, coref_f1: 0.5565, mention_recall: 0.9815, batch_loss: 525.8194, loss: 59.1900 ||: 100%|##########| 122/122 [00:06<00:00, 11.67it/s]
2022-05-15 01:41:58,443 - INFO - tqdm - coref_precision: 0.6608, coref_recall: 0.4913, coref_f1: 0.5565, mention_recall: 0.9815, batch_loss: 525.8194, loss: 59.1900 ||: 100%|##########| 122/122 [00:06<00:00, 18.48it/s]
2022-05-15 01:42:00,511 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.788  |     0.557
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.895  |     0.661
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.717  |     0.491
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - loss               |     9.404  |    59.190
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.982
2022-05-15 01:42:00,512 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.219  |       N/A
2022-05-15 01:42:00,512 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.252069
2022-05-15 01:42:00,512 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:59:03
2022-05-15 01:42:00,512 - INFO - allennlp.training.trainer - Epoch 12/149
2022-05-15 01:42:00,513 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:42:00,513 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:42:00,514 - INFO - allennlp.training.trainer - Training
2022-05-15 01:42:00,514 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:42:10,667 - INFO - tqdm - coref_precision: 0.9069, coref_recall: 0.7395, coref_f1: 0.8050, mention_recall: 0.9865, batch_loss: 6.1222, loss: 6.9098 ||:   9%|8         | 87/998 [00:10<01:50,  8.27it/s]
2022-05-15 01:42:20,758 - INFO - tqdm - coref_precision: 0.9200, coref_recall: 0.7494, coref_f1: 0.8150, mention_recall: 0.9888, batch_loss: 0.0000, loss: 6.0721 ||:  17%|#6        | 168/998 [00:20<01:19, 10.41it/s]
2022-05-15 01:42:30,803 - INFO - tqdm - coref_precision: 0.9238, coref_recall: 0.7590, coref_f1: 0.8227, mention_recall: 0.9899, batch_loss: 0.0000, loss: 5.4927 ||:  26%|##5       | 258/998 [00:30<01:10, 10.52it/s]
2022-05-15 01:42:40,850 - INFO - tqdm - coref_precision: 0.8972, coref_recall: 0.7283, coref_f1: 0.7961, mention_recall: 0.9907, batch_loss: 0.0000, loss: 9.0877 ||:  34%|###4      | 344/998 [00:40<01:07,  9.71it/s]
2022-05-15 01:42:50,873 - INFO - tqdm - coref_precision: 0.8925, coref_recall: 0.7330, coref_f1: 0.7966, mention_recall: 0.9898, batch_loss: 6.2010, loss: 8.7491 ||:  43%|####3     | 434/998 [00:50<01:05,  8.61it/s]
2022-05-15 01:43:00,985 - INFO - tqdm - coref_precision: 0.8957, coref_recall: 0.7269, coref_f1: 0.7939, mention_recall: 0.9885, batch_loss: 0.1672, loss: 8.8677 ||:  52%|#####1    | 517/998 [01:00<00:40, 11.98it/s]
2022-05-15 01:43:11,013 - INFO - tqdm - coref_precision: 0.8949, coref_recall: 0.7194, coref_f1: 0.7897, mention_recall: 0.9891, batch_loss: 4.7369, loss: 10.2910 ||:  59%|#####9    | 592/998 [01:10<00:42,  9.46it/s]
2022-05-15 01:43:21,308 - INFO - tqdm - coref_precision: 0.8940, coref_recall: 0.7194, coref_f1: 0.7895, mention_recall: 0.9897, batch_loss: 0.0000, loss: 9.9187 ||:  67%|######7   | 673/998 [01:20<01:21,  3.97it/s]
2022-05-15 01:43:31,360 - INFO - tqdm - coref_precision: 0.8970, coref_recall: 0.7222, coref_f1: 0.7921, mention_recall: 0.9897, batch_loss: 4.2721, loss: 9.4623 ||:  78%|#######7  | 775/998 [01:30<00:20, 11.04it/s]
2022-05-15 01:43:41,559 - INFO - tqdm - coref_precision: 0.8982, coref_recall: 0.7263, coref_f1: 0.7949, mention_recall: 0.9894, batch_loss: 6.9053, loss: 9.0078 ||:  86%|########6 | 861/998 [01:41<00:17,  7.94it/s]
2022-05-15 01:43:51,691 - INFO - tqdm - coref_precision: 0.8952, coref_recall: 0.7276, coref_f1: 0.7950, mention_recall: 0.9896, batch_loss: 0.0136, loss: 9.0629 ||:  95%|#########5| 949/998 [01:51<00:05,  9.42it/s]
2022-05-15 01:43:56,676 - INFO - tqdm - coref_precision: 0.8947, coref_recall: 0.7288, coref_f1: 0.7957, mention_recall: 0.9898, batch_loss: 0.0000, loss: 8.8987 ||: 100%|#########9| 994/998 [01:56<00:00,  9.73it/s]
2022-05-15 01:43:56,895 - INFO - tqdm - coref_precision: 0.8949, coref_recall: 0.7290, coref_f1: 0.7959, mention_recall: 0.9898, batch_loss: 0.0311, loss: 8.8811 ||: 100%|#########9| 996/998 [01:56<00:00,  9.54it/s]
2022-05-15 01:43:57,036 - INFO - tqdm - coref_precision: 0.8949, coref_recall: 0.7291, coref_f1: 0.7960, mention_recall: 0.9898, batch_loss: 0.0000, loss: 8.8633 ||: 100%|##########| 998/998 [01:56<00:00, 10.59it/s]
2022-05-15 01:43:57,036 - INFO - tqdm - coref_precision: 0.8949, coref_recall: 0.7291, coref_f1: 0.7960, mention_recall: 0.9898, batch_loss: 0.0000, loss: 8.8633 ||: 100%|##########| 998/998 [01:56<00:00,  8.56it/s]
2022-05-15 01:43:57,979 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:43:57,980 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:44:04,589 - INFO - tqdm - coref_precision: 0.6618, coref_recall: 0.4894, coref_f1: 0.5560, mention_recall: 0.9801, batch_loss: 48.0129, loss: 74.9451 ||: 100%|##########| 122/122 [00:06<00:00, 23.35it/s]
2022-05-15 01:44:04,590 - INFO - tqdm - coref_precision: 0.6618, coref_recall: 0.4894, coref_f1: 0.5560, mention_recall: 0.9801, batch_loss: 48.0129, loss: 74.9451 ||: 100%|##########| 122/122 [00:06<00:00, 18.46it/s]
2022-05-15 01:44:06,664 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:44:06,664 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.796  |     0.556
2022-05-15 01:44:06,664 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.895  |     0.662
2022-05-15 01:44:06,664 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.729  |     0.489
2022-05-15 01:44:06,665 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:44:06,665 - INFO - allennlp.training.callbacks.console_logger - loss               |     8.863  |    74.945
2022-05-15 01:44:06,665 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.990  |     0.980
2022-05-15 01:44:06,665 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.469  |       N/A
2022-05-15 01:44:06,665 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.152342
2022-05-15 01:44:06,665 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:56:13
2022-05-15 01:44:06,665 - INFO - allennlp.training.trainer - Epoch 13/149
2022-05-15 01:44:06,665 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:44:06,665 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:44:06,666 - INFO - allennlp.training.trainer - Training
2022-05-15 01:44:06,666 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:44:16,976 - INFO - tqdm - coref_precision: 0.8769, coref_recall: 0.7500, coref_f1: 0.7985, mention_recall: 0.9848, batch_loss: 0.0000, loss: 7.5296 ||:   8%|7         | 77/998 [00:10<03:22,  4.54it/s]
2022-05-15 01:44:27,102 - INFO - tqdm - coref_precision: 0.9022, coref_recall: 0.7597, coref_f1: 0.8161, mention_recall: 0.9883, batch_loss: 0.0000, loss: 7.2453 ||:  17%|#6        | 165/998 [00:20<01:33,  8.89it/s]
2022-05-15 01:44:37,233 - INFO - tqdm - coref_precision: 0.9016, coref_recall: 0.7442, coref_f1: 0.8061, mention_recall: 0.9889, batch_loss: 12.1230, loss: 6.9022 ||:  25%|##4       | 249/998 [00:30<01:27,  8.52it/s]
2022-05-15 01:44:47,260 - INFO - tqdm - coref_precision: 0.9068, coref_recall: 0.7423, coref_f1: 0.8075, mention_recall: 0.9900, batch_loss: 0.0004, loss: 6.9347 ||:  33%|###3      | 330/998 [00:40<01:13,  9.07it/s]
2022-05-15 01:44:57,794 - INFO - tqdm - coref_precision: 0.9094, coref_recall: 0.7481, coref_f1: 0.8120, mention_recall: 0.9899, batch_loss: 77.6978, loss: 6.7514 ||:  42%|####2     | 420/998 [00:51<01:41,  5.70it/s]
2022-05-15 01:45:08,326 - INFO - tqdm - coref_precision: 0.8965, coref_recall: 0.7299, coref_f1: 0.7973, mention_recall: 0.9898, batch_loss: 378.2821, loss: 9.0795 ||:  50%|#####     | 503/998 [01:01<02:43,  3.03it/s]
2022-05-15 01:45:18,367 - INFO - tqdm - coref_precision: 0.8958, coref_recall: 0.7299, coref_f1: 0.7970, mention_recall: 0.9894, batch_loss: 2.3999, loss: 8.9895 ||:  60%|#####9    | 594/998 [01:11<00:41,  9.69it/s]
2022-05-15 01:45:28,497 - INFO - tqdm - coref_precision: 0.8978, coref_recall: 0.7284, coref_f1: 0.7965, mention_recall: 0.9893, batch_loss: 0.1598, loss: 8.6011 ||:  68%|######8   | 682/998 [01:21<00:59,  5.32it/s]
2022-05-15 01:45:38,743 - INFO - tqdm - coref_precision: 0.8995, coref_recall: 0.7304, coref_f1: 0.7984, mention_recall: 0.9896, batch_loss: 0.0000, loss: 8.0094 ||:  77%|#######7  | 771/998 [01:32<00:25,  8.91it/s]
2022-05-15 01:45:48,917 - INFO - tqdm - coref_precision: 0.9016, coref_recall: 0.7257, coref_f1: 0.7964, mention_recall: 0.9897, batch_loss: 0.9597, loss: 8.4220 ||:  87%|########6 | 864/998 [01:42<00:16,  8.28it/s]
2022-05-15 01:45:59,032 - INFO - tqdm - coref_precision: 0.9043, coref_recall: 0.7302, coref_f1: 0.8002, mention_recall: 0.9900, batch_loss: 16.0263, loss: 8.0058 ||:  96%|#########5| 955/998 [01:52<00:06,  6.68it/s]
2022-05-15 01:46:02,922 - INFO - tqdm - coref_precision: 0.9059, coref_recall: 0.7324, coref_f1: 0.8021, mention_recall: 0.9899, batch_loss: 0.0001, loss: 7.9195 ||: 100%|#########9| 995/998 [01:56<00:00,  9.10it/s]
2022-05-15 01:46:03,164 - INFO - tqdm - coref_precision: 0.9062, coref_recall: 0.7330, coref_f1: 0.8026, mention_recall: 0.9899, batch_loss: 5.8781, loss: 7.9140 ||: 100%|#########9| 997/998 [01:56<00:00,  8.84it/s]
2022-05-15 01:46:03,245 - INFO - tqdm - coref_precision: 0.9063, coref_recall: 0.7332, coref_f1: 0.8028, mention_recall: 0.9899, batch_loss: 0.0009, loss: 7.9061 ||: 100%|##########| 998/998 [01:56<00:00,  8.56it/s]
2022-05-15 01:46:04,184 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:46:04,185 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:46:10,816 - INFO - tqdm - coref_precision: 0.6531, coref_recall: 0.4962, coref_f1: 0.5567, mention_recall: 0.9763, batch_loss: 84.1450, loss: 78.0856 ||: 100%|##########| 122/122 [00:06<00:00, 16.36it/s]
2022-05-15 01:46:10,816 - INFO - tqdm - coref_precision: 0.6531, coref_recall: 0.4962, coref_f1: 0.5567, mention_recall: 0.9763, batch_loss: 84.1450, loss: 78.0856 ||: 100%|##########| 122/122 [00:06<00:00, 18.40it/s]
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.803  |     0.557
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.906  |     0.653
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.733  |     0.496
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - loss               |     7.906  |    78.086
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.990  |     0.976
2022-05-15 01:46:12,900 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.469  |       N/A
2022-05-15 01:46:12,900 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.235590
2022-05-15 01:46:12,901 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:53:29
2022-05-15 01:46:12,901 - INFO - allennlp.training.trainer - Epoch 14/149
2022-05-15 01:46:12,901 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:46:12,901 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:46:12,902 - INFO - allennlp.training.trainer - Training
2022-05-15 01:46:12,902 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:46:22,944 - INFO - tqdm - coref_precision: 0.8646, coref_recall: 0.7612, coref_f1: 0.7993, mention_recall: 0.9903, batch_loss: 0.0000, loss: 9.0399 ||:   9%|8         | 85/998 [00:10<01:27, 10.38it/s]
2022-05-15 01:46:33,030 - INFO - tqdm - coref_precision: 0.8928, coref_recall: 0.7654, coref_f1: 0.8153, mention_recall: 0.9902, batch_loss: 0.0006, loss: 7.4883 ||:  16%|#6        | 161/998 [00:20<01:25,  9.83it/s]
2022-05-15 01:46:43,255 - INFO - tqdm - coref_precision: 0.9069, coref_recall: 0.7662, coref_f1: 0.8216, mention_recall: 0.9901, batch_loss: 0.0650, loss: 5.8352 ||:  26%|##5       | 259/998 [00:30<01:21,  9.04it/s]
2022-05-15 01:46:53,348 - INFO - tqdm - coref_precision: 0.9185, coref_recall: 0.7718, coref_f1: 0.8292, mention_recall: 0.9896, batch_loss: 0.0000, loss: 5.7771 ||:  35%|###5      | 352/998 [00:40<01:03, 10.12it/s]
2022-05-15 01:47:03,364 - INFO - tqdm - coref_precision: 0.9230, coref_recall: 0.7745, coref_f1: 0.8325, mention_recall: 0.9897, batch_loss: 0.5024, loss: 5.4696 ||:  44%|####4     | 443/998 [00:50<00:57,  9.62it/s]
2022-05-15 01:47:13,618 - INFO - tqdm - coref_precision: 0.9162, coref_recall: 0.7660, coref_f1: 0.8249, mention_recall: 0.9896, batch_loss: 184.4350, loss: 5.9916 ||:  54%|#####3    | 534/998 [01:00<00:53,  8.69it/s]
2022-05-15 01:47:23,701 - INFO - tqdm - coref_precision: 0.9178, coref_recall: 0.7623, coref_f1: 0.8235, mention_recall: 0.9888, batch_loss: 0.7737, loss: 5.9718 ||:  63%|######3   | 629/998 [01:10<00:39,  9.32it/s]
2022-05-15 01:47:33,721 - INFO - tqdm - coref_precision: 0.9192, coref_recall: 0.7623, coref_f1: 0.8245, mention_recall: 0.9889, batch_loss: 0.0000, loss: 5.7962 ||:  73%|#######3  | 729/998 [01:20<00:24, 11.18it/s]
2022-05-15 01:47:44,211 - INFO - tqdm - coref_precision: 0.9172, coref_recall: 0.7601, coref_f1: 0.8224, mention_recall: 0.9887, batch_loss: 47.5294, loss: 5.9671 ||:  79%|#######9  | 792/998 [01:31<00:53,  3.82it/s]
2022-05-15 01:47:54,217 - INFO - tqdm - coref_precision: 0.9149, coref_recall: 0.7496, coref_f1: 0.8155, mention_recall: 0.9886, batch_loss: 0.0000, loss: 6.9310 ||:  88%|########7 | 877/998 [01:41<00:16,  7.46it/s]
2022-05-15 01:48:04,282 - INFO - tqdm - coref_precision: 0.9157, coref_recall: 0.7454, coref_f1: 0.8138, mention_recall: 0.9889, batch_loss: 0.0000, loss: 7.6097 ||:  96%|#########5| 957/998 [01:51<00:03, 10.80it/s]
2022-05-15 01:48:09,135 - INFO - tqdm - coref_precision: 0.9153, coref_recall: 0.7440, coref_f1: 0.8126, mention_recall: 0.9887, batch_loss: 0.0000, loss: 7.5101 ||: 100%|#########9| 995/998 [01:56<00:00,  9.03it/s]
2022-05-15 01:48:09,277 - INFO - tqdm - coref_precision: 0.9153, coref_recall: 0.7441, coref_f1: 0.8127, mention_recall: 0.9887, batch_loss: 0.0000, loss: 7.4951 ||: 100%|#########9| 997/998 [01:56<00:00, 10.13it/s]
2022-05-15 01:48:09,344 - INFO - tqdm - coref_precision: 0.9154, coref_recall: 0.7442, coref_f1: 0.8128, mention_recall: 0.9887, batch_loss: 0.0000, loss: 7.4876 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:48:10,299 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:48:10,300 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:48:16,932 - INFO - tqdm - coref_precision: 0.6545, coref_recall: 0.5055, coref_f1: 0.5634, mention_recall: 0.9757, batch_loss: 68.9973, loss: 62.7960 ||: 100%|##########| 122/122 [00:06<00:00, 23.94it/s]
2022-05-15 01:48:16,932 - INFO - tqdm - coref_precision: 0.6545, coref_recall: 0.5055, coref_f1: 0.5634, mention_recall: 0.9757, batch_loss: 68.9973, loss: 62.7960 ||: 100%|##########| 122/122 [00:06<00:00, 18.40it/s]
2022-05-15 01:48:18,795 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.813  |     0.563
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.915  |     0.654
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.744  |     0.505
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - loss               |     7.488  |    62.796
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.976
2022-05-15 01:48:24,897 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.469  |       N/A
2022-05-15 01:48:24,898 - INFO - allennlp.training.trainer - Epoch duration: 0:02:11.996893
2022-05-15 01:48:24,898 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:51:42
2022-05-15 01:48:24,898 - INFO - allennlp.training.trainer - Epoch 15/149
2022-05-15 01:48:24,898 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:48:24,898 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:48:24,899 - INFO - allennlp.training.trainer - Training
2022-05-15 01:48:24,899 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:48:34,929 - INFO - tqdm - coref_precision: 0.9231, coref_recall: 0.7756, coref_f1: 0.8329, mention_recall: 0.9890, batch_loss: 0.0000, loss: 3.6845 ||:  10%|#         | 102/998 [00:10<01:38,  9.12it/s]
2022-05-15 01:48:44,952 - INFO - tqdm - coref_precision: 0.9161, coref_recall: 0.7507, coref_f1: 0.8150, mention_recall: 0.9881, batch_loss: 40.6462, loss: 3.9920 ||:  19%|#8        | 188/998 [00:20<01:46,  7.64it/s]
2022-05-15 01:48:56,150 - INFO - tqdm - coref_precision: 0.8971, coref_recall: 0.7139, coref_f1: 0.7883, mention_recall: 0.9881, batch_loss: 35.5909, loss: 8.3290 ||:  27%|##6       | 268/998 [00:31<03:51,  3.16it/s]
2022-05-15 01:49:06,182 - INFO - tqdm - coref_precision: 0.8967, coref_recall: 0.6943, coref_f1: 0.7767, mention_recall: 0.9875, batch_loss: 0.0000, loss: 10.6616 ||:  35%|###5      | 350/998 [00:41<00:56, 11.53it/s]
2022-05-15 01:49:16,217 - INFO - tqdm - coref_precision: 0.9021, coref_recall: 0.7119, coref_f1: 0.7896, mention_recall: 0.9877, batch_loss: 0.0000, loss: 9.6399 ||:  43%|####3     | 430/998 [00:51<01:19,  7.13it/s]
2022-05-15 01:49:26,356 - INFO - tqdm - coref_precision: 0.8995, coref_recall: 0.7190, coref_f1: 0.7928, mention_recall: 0.9880, batch_loss: 0.0000, loss: 9.2146 ||:  52%|#####1    | 516/998 [01:01<00:41, 11.54it/s]
2022-05-15 01:49:36,400 - INFO - tqdm - coref_precision: 0.9070, coref_recall: 0.7295, coref_f1: 0.8016, mention_recall: 0.9877, batch_loss: 0.2205, loss: 8.3167 ||:  62%|######1   | 614/998 [01:11<00:45,  8.50it/s]
2022-05-15 01:49:46,655 - INFO - tqdm - coref_precision: 0.9102, coref_recall: 0.7288, coref_f1: 0.8021, mention_recall: 0.9882, batch_loss: 5.4924, loss: 8.1899 ||:  70%|######9   | 695/998 [01:21<00:42,  7.06it/s]
2022-05-15 01:49:56,658 - INFO - tqdm - coref_precision: 0.9143, coref_recall: 0.7344, coref_f1: 0.8067, mention_recall: 0.9879, batch_loss: 0.0300, loss: 7.8857 ||:  78%|#######7  | 775/998 [01:31<00:24,  8.93it/s]
2022-05-15 01:50:06,694 - INFO - tqdm - coref_precision: 0.9173, coref_recall: 0.7407, coref_f1: 0.8118, mention_recall: 0.9880, batch_loss: 0.0332, loss: 7.3936 ||:  87%|########7 | 871/998 [01:41<00:10, 12.43it/s]
2022-05-15 01:50:16,933 - INFO - tqdm - coref_precision: 0.9203, coref_recall: 0.7439, coref_f1: 0.8148, mention_recall: 0.9883, batch_loss: 10.6230, loss: 7.1776 ||:  96%|#########5| 957/998 [01:52<00:04, 10.22it/s]
2022-05-15 01:50:21,088 - INFO - tqdm - coref_precision: 0.9207, coref_recall: 0.7452, coref_f1: 0.8157, mention_recall: 0.9884, batch_loss: 0.0989, loss: 7.0896 ||: 100%|#########9| 994/998 [01:56<00:00,  6.42it/s]
2022-05-15 01:50:21,215 - INFO - tqdm - coref_precision: 0.9207, coref_recall: 0.7452, coref_f1: 0.8157, mention_recall: 0.9884, batch_loss: 0.0000, loss: 7.0754 ||: 100%|#########9| 996/998 [01:56<00:00,  8.19it/s]
2022-05-15 01:50:21,398 - INFO - tqdm - coref_precision: 0.9208, coref_recall: 0.7453, coref_f1: 0.8158, mention_recall: 0.9884, batch_loss: 0.0006, loss: 7.0612 ||: 100%|##########| 998/998 [01:56<00:00,  8.97it/s]
2022-05-15 01:50:21,399 - INFO - tqdm - coref_precision: 0.9208, coref_recall: 0.7453, coref_f1: 0.8158, mention_recall: 0.9884, batch_loss: 0.0006, loss: 7.0612 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:50:22,339 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:50:22,340 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:50:28,969 - INFO - tqdm - coref_precision: 0.6669, coref_recall: 0.5009, coref_f1: 0.5648, mention_recall: 0.9755, batch_loss: 7.3360, loss: 85.3231 ||: 100%|##########| 122/122 [00:06<00:00, 18.40it/s]
2022-05-15 01:50:30,844 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.816  |     0.565
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.921  |     0.667
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.745  |     0.501
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:50:36,917 - INFO - allennlp.training.callbacks.console_logger - loss               |     7.061  |    85.323
2022-05-15 01:50:36,918 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.975
2022-05-15 01:50:36,918 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.719  |       N/A
2022-05-15 01:50:36,918 - INFO - allennlp.training.trainer - Epoch duration: 0:02:12.019925
2022-05-15 01:50:36,918 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:49:52
2022-05-15 01:50:36,918 - INFO - allennlp.training.trainer - Epoch 16/149
2022-05-15 01:50:36,918 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:50:36,918 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:50:36,919 - INFO - allennlp.training.trainer - Training
2022-05-15 01:50:36,919 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:50:46,928 - INFO - tqdm - coref_precision: 0.9088, coref_recall: 0.7417, coref_f1: 0.8102, mention_recall: 0.9879, batch_loss: 7.9788, loss: 5.3182 ||:   9%|8         | 87/998 [00:10<01:54,  7.98it/s]
2022-05-15 01:50:57,935 - INFO - tqdm - coref_precision: 0.9228, coref_recall: 0.7584, coref_f1: 0.8250, mention_recall: 0.9896, batch_loss: 158.5693, loss: 6.5991 ||:  17%|#7        | 173/998 [00:21<03:34,  3.84it/s]
2022-05-15 01:51:07,992 - INFO - tqdm - coref_precision: 0.9251, coref_recall: 0.7458, coref_f1: 0.8170, mention_recall: 0.9881, batch_loss: 7.2199, loss: 5.9442 ||:  25%|##5       | 250/998 [00:31<01:36,  7.72it/s]
2022-05-15 01:51:18,126 - INFO - tqdm - coref_precision: 0.9240, coref_recall: 0.7136, coref_f1: 0.7990, mention_recall: 0.9896, batch_loss: 0.0023, loss: 10.3230 ||:  34%|###4      | 340/998 [00:41<01:15,  8.73it/s]
2022-05-15 01:51:28,182 - INFO - tqdm - coref_precision: 0.9221, coref_recall: 0.7226, coref_f1: 0.8038, mention_recall: 0.9892, batch_loss: 0.0000, loss: 9.6199 ||:  42%|####2     | 422/998 [00:51<01:00,  9.59it/s]
2022-05-15 01:51:38,588 - INFO - tqdm - coref_precision: 0.9256, coref_recall: 0.7316, coref_f1: 0.8105, mention_recall: 0.9891, batch_loss: 94.1606, loss: 8.3777 ||:  52%|#####1    | 517/998 [01:01<02:05,  3.82it/s]
2022-05-15 01:51:48,765 - INFO - tqdm - coref_precision: 0.9276, coref_recall: 0.7372, coref_f1: 0.8141, mention_recall: 0.9895, batch_loss: 0.0130, loss: 7.8367 ||:  61%|######    | 605/998 [01:11<00:37, 10.36it/s]
2022-05-15 01:51:59,356 - INFO - tqdm - coref_precision: 0.9282, coref_recall: 0.7441, coref_f1: 0.8184, mention_recall: 0.9894, batch_loss: 46.7522, loss: 7.2448 ||:  70%|#######   | 701/998 [01:22<00:56,  5.23it/s]
2022-05-15 01:52:09,392 - INFO - tqdm - coref_precision: 0.9218, coref_recall: 0.7439, coref_f1: 0.8158, mention_recall: 0.9893, batch_loss: 9.8384, loss: 7.3313 ||:  78%|#######8  | 780/998 [01:32<00:51,  4.24it/s]
2022-05-15 01:52:19,435 - INFO - tqdm - coref_precision: 0.9180, coref_recall: 0.7417, coref_f1: 0.8127, mention_recall: 0.9895, batch_loss: 0.0000, loss: 7.5686 ||:  86%|########5 | 857/998 [01:42<00:14,  9.66it/s]
2022-05-15 01:52:29,588 - INFO - tqdm - coref_precision: 0.9222, coref_recall: 0.7477, coref_f1: 0.8179, mention_recall: 0.9891, batch_loss: 10.1956, loss: 6.9040 ||:  96%|#########6| 959/998 [01:52<00:03,  9.90it/s]
2022-05-15 01:52:32,961 - INFO - tqdm - coref_precision: 0.9230, coref_recall: 0.7490, coref_f1: 0.8190, mention_recall: 0.9891, batch_loss: 1.3721, loss: 6.7131 ||: 100%|#########9| 994/998 [01:56<00:00, 10.59it/s]
2022-05-15 01:52:33,163 - INFO - tqdm - coref_precision: 0.9231, coref_recall: 0.7490, coref_f1: 0.8189, mention_recall: 0.9891, batch_loss: 0.0000, loss: 6.7027 ||: 100%|#########9| 996/998 [01:56<00:00, 10.36it/s]
2022-05-15 01:52:33,400 - INFO - tqdm - coref_precision: 0.9224, coref_recall: 0.7490, coref_f1: 0.8187, mention_recall: 0.9891, batch_loss: 0.0000, loss: 6.7732 ||: 100%|##########| 998/998 [01:56<00:00,  9.68it/s]
2022-05-15 01:52:33,401 - INFO - tqdm - coref_precision: 0.9224, coref_recall: 0.7490, coref_f1: 0.8187, mention_recall: 0.9891, batch_loss: 0.0000, loss: 6.7732 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:52:34,345 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:52:34,346 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:52:40,966 - INFO - tqdm - coref_precision: 0.6640, coref_recall: 0.4942, coref_f1: 0.5598, mention_recall: 0.9708, batch_loss: 0.1095, loss: 93.6428 ||: 100%|##########| 122/122 [00:06<00:00, 18.43it/s]
2022-05-15 01:52:43,035 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.819  |     0.560
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.922  |     0.664
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.749  |     0.494
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - loss               |     6.773  |    93.643
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.989  |     0.971
2022-05-15 01:52:43,036 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.719  |       N/A
2022-05-15 01:52:43,036 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.118306
2022-05-15 01:52:43,036 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:47:14
2022-05-15 01:52:43,036 - INFO - allennlp.training.trainer - Epoch 17/149
2022-05-15 01:52:43,036 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:52:43,037 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:52:43,037 - INFO - allennlp.training.trainer - Training
2022-05-15 01:52:43,038 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:52:53,189 - INFO - tqdm - coref_precision: 0.8942, coref_recall: 0.7000, coref_f1: 0.7807, mention_recall: 0.9899, batch_loss: 0.0701, loss: 13.6759 ||:  10%|9         | 98/998 [00:10<01:39,  9.06it/s]
2022-05-15 01:53:03,284 - INFO - tqdm - coref_precision: 0.9154, coref_recall: 0.7364, coref_f1: 0.8096, mention_recall: 0.9907, batch_loss: 48.8056, loss: 9.2902 ||:  19%|#8        | 189/998 [00:20<01:31,  8.88it/s]
2022-05-15 01:53:13,384 - INFO - tqdm - coref_precision: 0.9256, coref_recall: 0.7469, coref_f1: 0.8196, mention_recall: 0.9898, batch_loss: 8.6188, loss: 7.5769 ||:  28%|##8       | 281/998 [00:30<01:54,  6.25it/s]
2022-05-15 01:53:24,288 - INFO - tqdm - coref_precision: 0.9221, coref_recall: 0.7517, coref_f1: 0.8211, mention_recall: 0.9903, batch_loss: 113.7336, loss: 7.1846 ||:  36%|###5      | 356/998 [00:41<03:27,  3.10it/s]
2022-05-15 01:53:34,346 - INFO - tqdm - coref_precision: 0.9239, coref_recall: 0.7579, coref_f1: 0.8253, mention_recall: 0.9894, batch_loss: 0.0000, loss: 6.5550 ||:  44%|####3     | 435/998 [00:51<01:01,  9.22it/s]
2022-05-15 01:53:44,627 - INFO - tqdm - coref_precision: 0.9223, coref_recall: 0.7482, coref_f1: 0.8190, mention_recall: 0.9883, batch_loss: 774.0986, loss: 7.5209 ||:  53%|#####2    | 528/998 [01:01<00:53,  8.74it/s]
2022-05-15 01:53:54,628 - INFO - tqdm - coref_precision: 0.9260, coref_recall: 0.7529, coref_f1: 0.8229, mention_recall: 0.9878, batch_loss: 0.0036, loss: 6.8885 ||:  62%|######1   | 614/998 [01:11<00:38,  9.87it/s]
2022-05-15 01:54:04,805 - INFO - tqdm - coref_precision: 0.9267, coref_recall: 0.7514, coref_f1: 0.8220, mention_recall: 0.9874, batch_loss: 0.0000, loss: 6.7618 ||:  70%|#######   | 703/998 [01:21<00:39,  7.45it/s]
2022-05-15 01:54:15,128 - INFO - tqdm - coref_precision: 0.9210, coref_recall: 0.7499, coref_f1: 0.8191, mention_recall: 0.9870, batch_loss: 27.3584, loss: 6.8821 ||:  79%|#######8  | 787/998 [01:32<00:27,  7.59it/s]
2022-05-15 01:54:25,777 - INFO - tqdm - coref_precision: 0.9157, coref_recall: 0.7476, coref_f1: 0.8156, mention_recall: 0.9872, batch_loss: 0.0024, loss: 6.9873 ||:  87%|########6 | 865/998 [01:42<00:26,  4.97it/s]
2022-05-15 01:54:35,942 - INFO - tqdm - coref_precision: 0.9194, coref_recall: 0.7524, coref_f1: 0.8197, mention_recall: 0.9872, batch_loss: 0.0000, loss: 6.7208 ||:  96%|#########6| 961/998 [01:52<00:03,  9.74it/s]
2022-05-15 01:54:39,147 - INFO - tqdm - coref_precision: 0.9209, coref_recall: 0.7545, coref_f1: 0.8213, mention_recall: 0.9870, batch_loss: 0.0103, loss: 6.5593 ||: 100%|#########9| 994/998 [01:56<00:00, 11.15it/s]
2022-05-15 01:54:39,310 - INFO - tqdm - coref_precision: 0.9210, coref_recall: 0.7546, coref_f1: 0.8214, mention_recall: 0.9870, batch_loss: 0.0000, loss: 6.5462 ||: 100%|#########9| 996/998 [01:56<00:00, 11.48it/s]
2022-05-15 01:54:39,494 - INFO - tqdm - coref_precision: 0.9211, coref_recall: 0.7548, coref_f1: 0.8216, mention_recall: 0.9870, batch_loss: 0.0010, loss: 6.5330 ||: 100%|##########| 998/998 [01:56<00:00, 11.27it/s]
2022-05-15 01:54:39,495 - INFO - tqdm - coref_precision: 0.9211, coref_recall: 0.7548, coref_f1: 0.8216, mention_recall: 0.9870, batch_loss: 0.0010, loss: 6.5330 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:54:40,438 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:54:40,439 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:54:47,071 - INFO - tqdm - coref_precision: 0.6656, coref_recall: 0.4900, coref_f1: 0.5580, mention_recall: 0.9719, batch_loss: 326.9473, loss: 89.4229 ||: 100%|##########| 122/122 [00:06<00:00, 18.40it/s]
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.822  |     0.558
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.921  |     0.666
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.755  |     0.490
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - loss               |     6.533  |    89.423
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.972
2022-05-15 01:54:49,138 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 01:54:49,138 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.102276
2022-05-15 01:54:49,139 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:44:39
2022-05-15 01:54:49,139 - INFO - allennlp.training.trainer - Epoch 18/149
2022-05-15 01:54:49,139 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:54:49,139 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:54:49,140 - INFO - allennlp.training.trainer - Training
2022-05-15 01:54:49,140 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:54:59,201 - INFO - tqdm - coref_precision: 0.9342, coref_recall: 0.7685, coref_f1: 0.8334, mention_recall: 0.9840, batch_loss: 0.0001, loss: 6.1002 ||:   9%|8         | 85/998 [00:10<01:38,  9.23it/s]
2022-05-15 01:55:09,556 - INFO - tqdm - coref_precision: 0.9212, coref_recall: 0.7705, coref_f1: 0.8295, mention_recall: 0.9834, batch_loss: 0.0003, loss: 5.3251 ||:  18%|#8        | 182/998 [00:20<01:28,  9.20it/s]
2022-05-15 01:55:19,699 - INFO - tqdm - coref_precision: 0.9165, coref_recall: 0.7376, coref_f1: 0.8097, mention_recall: 0.9865, batch_loss: 0.0329, loss: 7.9959 ||:  28%|##7       | 275/998 [00:30<01:12,  9.92it/s]
2022-05-15 01:55:29,989 - INFO - tqdm - coref_precision: 0.9180, coref_recall: 0.7335, coref_f1: 0.8077, mention_recall: 0.9863, batch_loss: 141.6535, loss: 7.6370 ||:  35%|###5      | 354/998 [00:40<01:21,  7.92it/s]
2022-05-15 01:55:40,146 - INFO - tqdm - coref_precision: 0.9174, coref_recall: 0.7366, coref_f1: 0.8096, mention_recall: 0.9866, batch_loss: 0.0047, loss: 7.0203 ||:  44%|####4     | 440/998 [00:51<00:55, 10.11it/s]
2022-05-15 01:55:50,147 - INFO - tqdm - coref_precision: 0.9236, coref_recall: 0.7469, coref_f1: 0.8180, mention_recall: 0.9873, batch_loss: 11.8361, loss: 6.5680 ||:  53%|#####2    | 524/998 [01:01<00:58,  8.16it/s]
2022-05-15 01:56:00,321 - INFO - tqdm - coref_precision: 0.9248, coref_recall: 0.7516, coref_f1: 0.8212, mention_recall: 0.9876, batch_loss: 37.6395, loss: 6.3811 ||:  60%|######    | 599/998 [01:11<01:01,  6.45it/s]
2022-05-15 01:56:10,407 - INFO - tqdm - coref_precision: 0.9254, coref_recall: 0.7429, coref_f1: 0.8166, mention_recall: 0.9882, batch_loss: 0.0000, loss: 7.0294 ||:  69%|######9   | 691/998 [01:21<00:38,  7.88it/s]
2022-05-15 01:56:20,409 - INFO - tqdm - coref_precision: 0.9283, coref_recall: 0.7465, coref_f1: 0.8196, mention_recall: 0.9883, batch_loss: 0.0000, loss: 6.6749 ||:  79%|#######8  | 784/998 [01:31<00:21,  9.75it/s]
2022-05-15 01:56:30,966 - INFO - tqdm - coref_precision: 0.9308, coref_recall: 0.7508, coref_f1: 0.8232, mention_recall: 0.9882, batch_loss: 32.1999, loss: 6.1691 ||:  89%|########8 | 886/998 [01:41<00:22,  5.00it/s]
2022-05-15 01:56:41,887 - INFO - tqdm - coref_precision: 0.9248, coref_recall: 0.7492, coref_f1: 0.8200, mention_recall: 0.9885, batch_loss: 0.0000, loss: 6.4949 ||:  96%|#########6| 961/998 [01:52<00:09,  3.84it/s]
2022-05-15 01:56:45,269 - INFO - tqdm - coref_precision: 0.9264, coref_recall: 0.7522, coref_f1: 0.8225, mention_recall: 0.9884, batch_loss: 0.0079, loss: 6.3040 ||: 100%|#########9| 995/998 [01:56<00:00, 11.91it/s]
2022-05-15 01:56:45,461 - INFO - tqdm - coref_precision: 0.9265, coref_recall: 0.7526, coref_f1: 0.8228, mention_recall: 0.9885, batch_loss: 0.0013, loss: 6.2968 ||: 100%|#########9| 997/998 [01:56<00:00, 11.40it/s]
2022-05-15 01:56:45,559 - INFO - tqdm - coref_precision: 0.9266, coref_recall: 0.7527, coref_f1: 0.8229, mention_recall: 0.9885, batch_loss: 0.0004, loss: 6.2905 ||: 100%|##########| 998/998 [01:56<00:00,  8.57it/s]
2022-05-15 01:56:46,506 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:56:46,507 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:56:53,139 - INFO - tqdm - coref_precision: 0.6638, coref_recall: 0.5007, coref_f1: 0.5623, mention_recall: 0.9790, batch_loss: 18.4923, loss: 91.2010 ||: 100%|##########| 122/122 [00:06<00:00, 18.40it/s]
2022-05-15 01:56:55,191 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.823  |     0.562
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.927  |     0.664
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.753  |     0.501
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - loss               |     6.291  |    91.201
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.979
2022-05-15 01:56:55,192 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 01:56:55,192 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.053658
2022-05-15 01:56:55,192 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:42:06
2022-05-15 01:56:55,192 - INFO - allennlp.training.trainer - Epoch 19/149
2022-05-15 01:56:55,193 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:56:55,193 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:56:55,194 - INFO - allennlp.training.trainer - Training
2022-05-15 01:56:55,194 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:57:05,355 - INFO - tqdm - coref_precision: 0.9140, coref_recall: 0.6715, coref_f1: 0.7691, mention_recall: 0.9864, batch_loss: 11.5258, loss: 14.0715 ||:   9%|8         | 87/998 [00:10<01:50,  8.22it/s]
2022-05-15 01:57:15,598 - INFO - tqdm - coref_precision: 0.9348, coref_recall: 0.7322, coref_f1: 0.8149, mention_recall: 0.9867, batch_loss: 0.0000, loss: 7.6667 ||:  18%|#8        | 183/998 [00:20<01:36,  8.43it/s]
2022-05-15 01:57:25,636 - INFO - tqdm - coref_precision: 0.9446, coref_recall: 0.7571, coref_f1: 0.8330, mention_recall: 0.9875, batch_loss: 0.0000, loss: 5.9726 ||:  27%|##7       | 272/998 [00:30<02:25,  4.98it/s]
2022-05-15 01:57:35,737 - INFO - tqdm - coref_precision: 0.9244, coref_recall: 0.7284, coref_f1: 0.8086, mention_recall: 0.9874, batch_loss: 0.0000, loss: 9.6825 ||:  34%|###4      | 343/998 [00:40<01:10,  9.31it/s]
2022-05-15 01:57:45,802 - INFO - tqdm - coref_precision: 0.9297, coref_recall: 0.7387, coref_f1: 0.8164, mention_recall: 0.9872, batch_loss: 0.0000, loss: 8.2813 ||:  44%|####3     | 435/998 [00:50<01:06,  8.47it/s]
2022-05-15 01:57:55,869 - INFO - tqdm - coref_precision: 0.9220, coref_recall: 0.7381, coref_f1: 0.8128, mention_recall: 0.9874, batch_loss: 0.0000, loss: 8.1302 ||:  51%|#####1    | 513/998 [01:00<00:42, 11.42it/s]
2022-05-15 01:58:05,885 - INFO - tqdm - coref_precision: 0.9262, coref_recall: 0.7456, coref_f1: 0.8192, mention_recall: 0.9877, batch_loss: 0.0006, loss: 7.3954 ||:  59%|#####8    | 588/998 [01:10<01:00,  6.75it/s]
2022-05-15 01:58:16,010 - INFO - tqdm - coref_precision: 0.9273, coref_recall: 0.7504, coref_f1: 0.8220, mention_recall: 0.9880, batch_loss: 32.0489, loss: 6.9376 ||:  69%|######8   | 684/998 [01:20<01:00,  5.22it/s]
2022-05-15 01:58:26,021 - INFO - tqdm - coref_precision: 0.9263, coref_recall: 0.7449, coref_f1: 0.8182, mention_recall: 0.9877, batch_loss: 0.0004, loss: 6.8374 ||:  77%|#######6  | 767/998 [01:30<00:28,  8.22it/s]
2022-05-15 01:58:36,146 - INFO - tqdm - coref_precision: 0.9282, coref_recall: 0.7522, coref_f1: 0.8233, mention_recall: 0.9877, batch_loss: 0.0057, loss: 6.4594 ||:  86%|########6 | 860/998 [01:40<00:14,  9.77it/s]
2022-05-15 01:58:46,798 - INFO - tqdm - coref_precision: 0.9306, coref_recall: 0.7563, coref_f1: 0.8266, mention_recall: 0.9877, batch_loss: 0.0000, loss: 6.0798 ||:  95%|#########5| 952/998 [01:51<00:09,  4.79it/s]
2022-05-15 01:58:51,599 - INFO - tqdm - coref_precision: 0.9309, coref_recall: 0.7572, coref_f1: 0.8273, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.9501 ||: 100%|#########9| 995/998 [01:56<00:00,  9.78it/s]
2022-05-15 01:58:51,727 - INFO - tqdm - coref_precision: 0.9309, coref_recall: 0.7572, coref_f1: 0.8273, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.9382 ||: 100%|#########9| 997/998 [01:56<00:00, 11.04it/s]
2022-05-15 01:58:51,789 - INFO - tqdm - coref_precision: 0.9309, coref_recall: 0.7572, coref_f1: 0.8273, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.9322 ||: 100%|##########| 998/998 [01:56<00:00,  8.56it/s]
2022-05-15 01:58:52,753 - INFO - allennlp.training.trainer - Validating
2022-05-15 01:58:52,755 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 01:58:59,395 - INFO - tqdm - coref_precision: 0.6513, coref_recall: 0.5144, coref_f1: 0.5669, mention_recall: 0.9793, batch_loss: 128.1130, loss: 93.0282 ||: 100%|##########| 122/122 [00:06<00:00, 18.37it/s]
2022-05-15 01:59:01,268 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'rucoref_model_trained/best.th'.
2022-05-15 01:59:07,334 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 01:59:07,334 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.827  |     0.567
2022-05-15 01:59:07,334 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.931  |     0.651
2022-05-15 01:59:07,334 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.757  |     0.514
2022-05-15 01:59:07,334 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 01:59:07,335 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.932  |    93.028
2022-05-15 01:59:07,335 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.979
2022-05-15 01:59:07,335 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 01:59:07,335 - INFO - allennlp.training.trainer - Epoch duration: 0:02:12.142335
2022-05-15 01:59:07,335 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:40:16
2022-05-15 01:59:07,335 - INFO - allennlp.training.trainer - Epoch 20/149
2022-05-15 01:59:07,335 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 01:59:07,335 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 01:59:07,336 - INFO - allennlp.training.trainer - Training
2022-05-15 01:59:07,337 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 01:59:17,500 - INFO - tqdm - coref_precision: 0.9443, coref_recall: 0.8071, coref_f1: 0.8624, mention_recall: 0.9873, batch_loss: 0.0002, loss: 3.4214 ||:  10%|9         | 95/998 [00:10<01:28, 10.16it/s]
2022-05-15 01:59:27,545 - INFO - tqdm - coref_precision: 0.9463, coref_recall: 0.8090, coref_f1: 0.8638, mention_recall: 0.9895, batch_loss: 0.0000, loss: 3.0828 ||:  19%|#8        | 189/998 [00:20<01:08, 11.78it/s]
2022-05-15 01:59:37,581 - INFO - tqdm - coref_precision: 0.9485, coref_recall: 0.8033, coref_f1: 0.8594, mention_recall: 0.9878, batch_loss: 22.8502, loss: 2.8301 ||:  29%|##8       | 289/998 [00:30<01:42,  6.93it/s]
2022-05-15 01:59:47,671 - INFO - tqdm - coref_precision: 0.9523, coref_recall: 0.8066, coref_f1: 0.8625, mention_recall: 0.9870, batch_loss: 0.0000, loss: 2.5748 ||:  38%|###8      | 381/998 [00:40<00:55, 11.11it/s]
2022-05-15 01:59:57,825 - INFO - tqdm - coref_precision: 0.9508, coref_recall: 0.8019, coref_f1: 0.8594, mention_recall: 0.9869, batch_loss: 0.0008, loss: 2.7361 ||:  48%|####7     | 475/998 [00:50<00:50, 10.28it/s]
2022-05-15 02:00:08,063 - INFO - tqdm - coref_precision: 0.9500, coref_recall: 0.7970, coref_f1: 0.8568, mention_recall: 0.9864, batch_loss: 21.7436, loss: 2.9887 ||:  56%|#####5    | 558/998 [01:00<01:24,  5.19it/s]
2022-05-15 02:00:18,154 - INFO - tqdm - coref_precision: 0.9429, coref_recall: 0.7923, coref_f1: 0.8512, mention_recall: 0.9870, batch_loss: 0.0000, loss: 3.4058 ||:  64%|######3   | 636/998 [01:10<00:31, 11.66it/s]
2022-05-15 02:00:28,639 - INFO - tqdm - coref_precision: 0.9365, coref_recall: 0.7758, coref_f1: 0.8395, mention_recall: 0.9869, batch_loss: 9.8196, loss: 4.7704 ||:  72%|#######2  | 720/998 [01:21<00:59,  4.69it/s]
2022-05-15 02:00:38,734 - INFO - tqdm - coref_precision: 0.9355, coref_recall: 0.7680, coref_f1: 0.8345, mention_recall: 0.9872, batch_loss: 0.0006, loss: 5.4870 ||:  81%|########  | 805/998 [01:31<00:18, 10.50it/s]
2022-05-15 02:00:49,326 - INFO - tqdm - coref_precision: 0.9296, coref_recall: 0.7632, coref_f1: 0.8297, mention_recall: 0.9875, batch_loss: 94.6283, loss: 5.7998 ||:  88%|########8 | 880/998 [01:41<00:40,  2.93it/s]
2022-05-15 02:00:59,331 - INFO - tqdm - coref_precision: 0.9295, coref_recall: 0.7629, coref_f1: 0.8296, mention_recall: 0.9880, batch_loss: 0.0000, loss: 5.6745 ||:  97%|#########6| 967/998 [01:51<00:02, 13.92it/s]
2022-05-15 02:01:03,001 - INFO - tqdm - coref_precision: 0.9290, coref_recall: 0.7624, coref_f1: 0.8292, mention_recall: 0.9880, batch_loss: 0.0001, loss: 5.7339 ||: 100%|#########9| 994/998 [01:55<00:00,  6.67it/s]
2022-05-15 02:01:03,130 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7624, coref_f1: 0.8292, mention_recall: 0.9880, batch_loss: 0.0000, loss: 5.7224 ||: 100%|#########9| 996/998 [01:55<00:00,  8.47it/s]
2022-05-15 02:01:03,266 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7624, coref_f1: 0.8292, mention_recall: 0.9880, batch_loss: 0.0000, loss: 5.7109 ||: 100%|##########| 998/998 [01:55<00:00,  9.92it/s]
2022-05-15 02:01:03,267 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7624, coref_f1: 0.8292, mention_recall: 0.9880, batch_loss: 0.0000, loss: 5.7109 ||: 100%|##########| 998/998 [01:55<00:00,  8.61it/s]
2022-05-15 02:01:04,218 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:01:04,220 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:01:11,720 - INFO - tqdm - coref_precision: 0.6621, coref_recall: 0.4956, coref_f1: 0.5593, mention_recall: 0.9771, batch_loss: 74.7145, loss: 92.4493 ||: 100%|##########| 122/122 [00:07<00:00, 16.27it/s]
2022-05-15 02:01:13,812 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.829  |     0.559
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.929  |     0.662
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.762  |     0.496
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.711  |    92.449
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.977
2022-05-15 02:01:13,813 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:01:13,813 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.478082
2022-05-15 02:01:13,813 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:37:49
2022-05-15 02:01:13,813 - INFO - allennlp.training.trainer - Epoch 21/149
2022-05-15 02:01:13,813 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:01:13,814 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:01:13,815 - INFO - allennlp.training.trainer - Training
2022-05-15 02:01:13,815 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:01:23,867 - INFO - tqdm - coref_precision: 0.9302, coref_recall: 0.7509, coref_f1: 0.8212, mention_recall: 0.9904, batch_loss: 0.0000, loss: 6.0565 ||:   8%|8         | 83/998 [00:10<01:28, 10.37it/s]
2022-05-15 02:01:33,955 - INFO - tqdm - coref_precision: 0.9397, coref_recall: 0.7757, coref_f1: 0.8400, mention_recall: 0.9864, batch_loss: 0.0000, loss: 4.1885 ||:  18%|#7        | 178/998 [00:20<01:24,  9.69it/s]
2022-05-15 02:01:44,137 - INFO - tqdm - coref_precision: 0.9184, coref_recall: 0.7645, coref_f1: 0.8263, mention_recall: 0.9894, batch_loss: 46.4857, loss: 5.1399 ||:  25%|##5       | 250/998 [00:30<01:57,  6.35it/s]
2022-05-15 02:01:54,727 - INFO - tqdm - coref_precision: 0.9138, coref_recall: 0.7273, coref_f1: 0.8031, mention_recall: 0.9887, batch_loss: 11.3632, loss: 9.5665 ||:  33%|###3      | 334/998 [00:40<02:07,  5.22it/s]
2022-05-15 02:02:04,732 - INFO - tqdm - coref_precision: 0.9192, coref_recall: 0.7354, coref_f1: 0.8098, mention_recall: 0.9888, batch_loss: 0.0000, loss: 8.4279 ||:  41%|####1     | 414/998 [00:50<00:53, 10.97it/s]
2022-05-15 02:02:14,849 - INFO - tqdm - coref_precision: 0.9142, coref_recall: 0.7356, coref_f1: 0.8079, mention_recall: 0.9882, batch_loss: 0.0000, loss: 7.9507 ||:  50%|####9     | 496/998 [01:01<00:50,  9.94it/s]
2022-05-15 02:02:24,970 - INFO - tqdm - coref_precision: 0.9160, coref_recall: 0.7429, coref_f1: 0.8129, mention_recall: 0.9886, batch_loss: 0.0000, loss: 7.2625 ||:  59%|#####8    | 586/998 [01:11<00:54,  7.51it/s]
2022-05-15 02:02:35,121 - INFO - tqdm - coref_precision: 0.9193, coref_recall: 0.7486, coref_f1: 0.8177, mention_recall: 0.9886, batch_loss: 0.0000, loss: 6.6919 ||:  68%|######8   | 681/998 [01:21<00:28, 11.23it/s]
2022-05-15 02:02:45,228 - INFO - tqdm - coref_precision: 0.9239, coref_recall: 0.7553, coref_f1: 0.8235, mention_recall: 0.9889, batch_loss: 6.3252, loss: 6.0157 ||:  78%|#######8  | 781/998 [01:31<00:23,  9.31it/s]
2022-05-15 02:02:55,492 - INFO - tqdm - coref_precision: 0.9270, coref_recall: 0.7575, coref_f1: 0.8261, mention_recall: 0.9887, batch_loss: 1.4759, loss: 5.7671 ||:  87%|########7 | 870/998 [01:41<00:16,  8.00it/s]
2022-05-15 02:03:05,600 - INFO - tqdm - coref_precision: 0.9298, coref_recall: 0.7604, coref_f1: 0.8287, mention_recall: 0.9881, batch_loss: 0.0000, loss: 5.4174 ||:  97%|#########6| 966/998 [01:51<00:02, 11.18it/s]
2022-05-15 02:03:09,039 - INFO - tqdm - coref_precision: 0.9288, coref_recall: 0.7593, coref_f1: 0.8278, mention_recall: 0.9878, batch_loss: 0.0000, loss: 5.4228 ||: 100%|#########9| 994/998 [01:55<00:00,  8.80it/s]
2022-05-15 02:03:09,477 - INFO - tqdm - coref_precision: 0.9290, coref_recall: 0.7595, coref_f1: 0.8279, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.4120 ||: 100%|#########9| 996/998 [01:55<00:00,  6.88it/s]
2022-05-15 02:03:09,620 - INFO - tqdm - coref_precision: 0.9290, coref_recall: 0.7595, coref_f1: 0.8279, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.4011 ||: 100%|##########| 998/998 [01:55<00:00,  8.12it/s]
2022-05-15 02:03:09,620 - INFO - tqdm - coref_precision: 0.9290, coref_recall: 0.7595, coref_f1: 0.8279, mention_recall: 0.9877, batch_loss: 0.0000, loss: 5.4011 ||: 100%|##########| 998/998 [01:55<00:00,  8.62it/s]
2022-05-15 02:03:10,580 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:03:10,581 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:03:18,050 - INFO - tqdm - coref_precision: 0.6389, coref_recall: 0.5030, coref_f1: 0.5555, mention_recall: 0.9738, batch_loss: 32.2369, loss: 92.7712 ||: 100%|##########| 122/122 [00:07<00:00, 16.33it/s]
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.828  |     0.556
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.929  |     0.639
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.759  |     0.503
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.401  |    92.771
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.974
2022-05-15 02:03:20,104 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:03:20,104 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.291077
2022-05-15 02:03:20,104 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:35:23
2022-05-15 02:03:20,104 - INFO - allennlp.training.trainer - Epoch 22/149
2022-05-15 02:03:20,105 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:03:20,105 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:03:20,106 - INFO - allennlp.training.trainer - Training
2022-05-15 02:03:20,106 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:03:30,247 - INFO - tqdm - coref_precision: 0.8938, coref_recall: 0.7394, coref_f1: 0.8035, mention_recall: 0.9880, batch_loss: 0.0000, loss: 5.0163 ||:   9%|9         | 93/998 [00:10<01:13, 12.29it/s]
2022-05-15 02:03:40,466 - INFO - tqdm - coref_precision: 0.9230, coref_recall: 0.7524, coref_f1: 0.8221, mention_recall: 0.9865, batch_loss: 0.0002, loss: 3.9682 ||:  19%|#8        | 186/998 [00:20<01:20, 10.03it/s]
2022-05-15 02:03:50,543 - INFO - tqdm - coref_precision: 0.9322, coref_recall: 0.7784, coref_f1: 0.8408, mention_recall: 0.9896, batch_loss: 4.1732, loss: 3.6940 ||:  27%|##7       | 274/998 [00:30<01:07, 10.67it/s]
2022-05-15 02:04:00,685 - INFO - tqdm - coref_precision: 0.9330, coref_recall: 0.7707, coref_f1: 0.8353, mention_recall: 0.9880, batch_loss: 0.3582, loss: 4.1279 ||:  35%|###5      | 353/998 [00:40<01:47,  6.02it/s]
2022-05-15 02:04:10,774 - INFO - tqdm - coref_precision: 0.9309, coref_recall: 0.7632, coref_f1: 0.8304, mention_recall: 0.9877, batch_loss: 0.1611, loss: 4.4058 ||:  44%|####4     | 443/998 [00:50<00:50, 10.95it/s]
2022-05-15 02:04:20,869 - INFO - tqdm - coref_precision: 0.9373, coref_recall: 0.7715, coref_f1: 0.8375, mention_recall: 0.9874, batch_loss: 0.0000, loss: 3.8396 ||:  54%|#####4    | 539/998 [01:00<00:55,  8.21it/s]
2022-05-15 02:04:30,933 - INFO - tqdm - coref_precision: 0.9355, coref_recall: 0.7629, coref_f1: 0.8319, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.0360 ||:  63%|######3   | 629/998 [01:10<00:33, 11.11it/s]
2022-05-15 02:04:41,162 - INFO - tqdm - coref_precision: 0.9259, coref_recall: 0.7545, coref_f1: 0.8234, mention_recall: 0.9874, batch_loss: 0.0105, loss: 6.1742 ||:  71%|#######1  | 710/998 [01:21<00:36,  7.98it/s]
2022-05-15 02:04:51,493 - INFO - tqdm - coref_precision: 0.9260, coref_recall: 0.7577, coref_f1: 0.8256, mention_recall: 0.9875, batch_loss: 41.7325, loss: 6.0564 ||:  79%|#######8  | 787/998 [01:31<00:35,  6.03it/s]
2022-05-15 02:05:01,713 - INFO - tqdm - coref_precision: 0.9273, coref_recall: 0.7602, coref_f1: 0.8276, mention_recall: 0.9870, batch_loss: 8.8092, loss: 5.6813 ||:  89%|########8 | 884/998 [01:41<00:12,  9.48it/s]
2022-05-15 02:05:11,745 - INFO - tqdm - coref_precision: 0.9281, coref_recall: 0.7626, coref_f1: 0.8293, mention_recall: 0.9874, batch_loss: 0.0000, loss: 5.5278 ||:  96%|#########5| 957/998 [01:51<00:05,  7.21it/s]
2022-05-15 02:05:15,653 - INFO - tqdm - coref_precision: 0.9297, coref_recall: 0.7639, coref_f1: 0.8306, mention_recall: 0.9872, batch_loss: 0.0000, loss: 5.4001 ||: 100%|#########9| 995/998 [01:55<00:00, 11.10it/s]
2022-05-15 02:05:15,903 - INFO - tqdm - coref_precision: 0.9292, coref_recall: 0.7637, coref_f1: 0.8303, mention_recall: 0.9873, batch_loss: 44.5284, loss: 5.4340 ||: 100%|#########9| 997/998 [01:55<00:00,  9.93it/s]
2022-05-15 02:05:15,969 - INFO - tqdm - coref_precision: 0.9292, coref_recall: 0.7637, coref_f1: 0.8303, mention_recall: 0.9873, batch_loss: 0.0000, loss: 5.4285 ||: 100%|##########| 998/998 [01:55<00:00,  8.61it/s]
2022-05-15 02:05:16,914 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:05:16,915 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:05:24,377 - INFO - tqdm - coref_precision: 0.6560, coref_recall: 0.4948, coref_f1: 0.5574, mention_recall: 0.9752, batch_loss: 12.3281, loss: 90.9525 ||: 100%|##########| 122/122 [00:07<00:00, 16.35it/s]
2022-05-15 02:05:26,459 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:05:26,459 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.830  |     0.557
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.929  |     0.656
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.764  |     0.495
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.429  |    90.952
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.975
2022-05-15 02:05:26,460 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:05:26,460 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.355509
2022-05-15 02:05:26,460 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:32:59
2022-05-15 02:05:26,460 - INFO - allennlp.training.trainer - Epoch 23/149
2022-05-15 02:05:26,460 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:05:26,461 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:05:26,461 - INFO - allennlp.training.trainer - Training
2022-05-15 02:05:26,462 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:05:36,805 - INFO - tqdm - coref_precision: 0.9389, coref_recall: 0.7872, coref_f1: 0.8500, mention_recall: 0.9863, batch_loss: 1.8717, loss: 2.1316 ||:  10%|9         | 98/998 [00:10<01:56,  7.74it/s]
2022-05-15 02:05:46,973 - INFO - tqdm - coref_precision: 0.9400, coref_recall: 0.7903, coref_f1: 0.8519, mention_recall: 0.9859, batch_loss: 1.6006, loss: 3.1697 ||:  17%|#7        | 174/998 [00:20<02:15,  6.08it/s]
2022-05-15 02:05:57,409 - INFO - tqdm - coref_precision: 0.9424, coref_recall: 0.7889, coref_f1: 0.8511, mention_recall: 0.9859, batch_loss: 14.9447, loss: 2.9773 ||:  26%|##6       | 261/998 [00:30<02:12,  5.54it/s]
2022-05-15 02:06:07,452 - INFO - tqdm - coref_precision: 0.9458, coref_recall: 0.7867, coref_f1: 0.8502, mention_recall: 0.9847, batch_loss: 0.0000, loss: 2.7826 ||:  36%|###5      | 358/998 [00:40<00:53, 11.87it/s]
2022-05-15 02:06:17,512 - INFO - tqdm - coref_precision: 0.9499, coref_recall: 0.7905, coref_f1: 0.8536, mention_recall: 0.9857, batch_loss: 0.0000, loss: 2.7280 ||:  46%|####5     | 455/998 [00:51<01:08,  7.89it/s]
2022-05-15 02:06:27,641 - INFO - tqdm - coref_precision: 0.9387, coref_recall: 0.7801, coref_f1: 0.8433, mention_recall: 0.9862, batch_loss: 3.7426, loss: 3.2686 ||:  53%|#####3    | 533/998 [01:01<01:12,  6.38it/s]
2022-05-15 02:06:37,689 - INFO - tqdm - coref_precision: 0.9390, coref_recall: 0.7822, coref_f1: 0.8447, mention_recall: 0.9868, batch_loss: 0.0044, loss: 3.4390 ||:  62%|######1   | 614/998 [01:11<01:01,  6.22it/s]
2022-05-15 02:06:47,701 - INFO - tqdm - coref_precision: 0.9410, coref_recall: 0.7838, coref_f1: 0.8463, mention_recall: 0.9867, batch_loss: 0.0000, loss: 3.3101 ||:  71%|#######   | 708/998 [01:21<00:26, 10.90it/s]
2022-05-15 02:06:57,774 - INFO - tqdm - coref_precision: 0.9442, coref_recall: 0.7884, coref_f1: 0.8501, mention_recall: 0.9863, batch_loss: 0.0000, loss: 3.0306 ||:  81%|########1 | 810/998 [01:31<00:16, 11.44it/s]
2022-05-15 02:07:08,066 - INFO - tqdm - coref_precision: 0.9385, coref_recall: 0.7860, coref_f1: 0.8465, mention_recall: 0.9867, batch_loss: 281.3698, loss: 3.4524 ||:  87%|########7 | 870/998 [01:41<00:41,  3.12it/s]
2022-05-15 02:07:18,157 - INFO - tqdm - coref_precision: 0.9286, coref_recall: 0.7693, coref_f1: 0.8328, mention_recall: 0.9870, batch_loss: 0.7468, loss: 5.2674 ||:  96%|#########5| 958/998 [01:51<00:04,  9.50it/s]
2022-05-15 02:07:22,328 - INFO - tqdm - coref_precision: 0.9288, coref_recall: 0.7696, coref_f1: 0.8331, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.2147 ||: 100%|#########9| 994/998 [01:55<00:00,  8.87it/s]
2022-05-15 02:07:22,572 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7703, coref_f1: 0.8337, mention_recall: 0.9870, batch_loss: 1.2176, loss: 5.2145 ||: 100%|#########9| 996/998 [01:56<00:00,  8.66it/s]
2022-05-15 02:07:22,712 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7703, coref_f1: 0.8336, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.2040 ||: 100%|##########| 998/998 [01:56<00:00,  9.81it/s]
2022-05-15 02:07:22,713 - INFO - tqdm - coref_precision: 0.9291, coref_recall: 0.7703, coref_f1: 0.8336, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.2040 ||: 100%|##########| 998/998 [01:56<00:00,  8.58it/s]
2022-05-15 02:07:23,658 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:07:23,659 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:07:30,336 - INFO - tqdm - coref_precision: 0.6522, coref_recall: 0.4961, coref_f1: 0.5568, mention_recall: 0.9738, batch_loss: 0.0000, loss: 95.8437 ||: 100%|##########| 122/122 [00:06<00:00, 18.27it/s]
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.834  |     0.557
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.929  |     0.652
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.770  |     0.496
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.204  |    95.844
2022-05-15 02:07:32,428 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.974
2022-05-15 02:07:32,429 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:07:32,429 - INFO - allennlp.training.trainer - Epoch duration: 0:02:05.968418
2022-05-15 02:07:32,429 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:30:34
2022-05-15 02:07:32,429 - INFO - allennlp.training.trainer - Epoch 24/149
2022-05-15 02:07:32,429 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:07:32,429 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:07:32,430 - INFO - allennlp.training.trainer - Training
2022-05-15 02:07:32,430 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:07:42,539 - INFO - tqdm - coref_precision: 0.9508, coref_recall: 0.7809, coref_f1: 0.8486, mention_recall: 0.9910, batch_loss: 0.0000, loss: 3.4429 ||:   8%|8         | 83/998 [00:10<01:19, 11.48it/s]
2022-05-15 02:07:52,715 - INFO - tqdm - coref_precision: 0.9456, coref_recall: 0.7823, coref_f1: 0.8471, mention_recall: 0.9878, batch_loss: 3.2305, loss: 3.1118 ||:  19%|#8        | 185/998 [00:20<01:13, 11.12it/s]
2022-05-15 02:08:02,972 - INFO - tqdm - coref_precision: 0.9467, coref_recall: 0.7887, coref_f1: 0.8508, mention_recall: 0.9845, batch_loss: 9.2831, loss: 3.1142 ||:  28%|##8       | 280/998 [00:30<01:42,  6.99it/s]
2022-05-15 02:08:13,772 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7632, coref_f1: 0.8314, mention_recall: 0.9864, batch_loss: 100.4855, loss: 5.9829 ||:  36%|###6      | 360/998 [00:41<02:39,  3.99it/s]
2022-05-15 02:08:24,052 - INFO - tqdm - coref_precision: 0.9366, coref_recall: 0.7655, coref_f1: 0.8345, mention_recall: 0.9860, batch_loss: 0.0000, loss: 5.2456 ||:  45%|####4     | 447/998 [00:51<01:38,  5.61it/s]
2022-05-15 02:08:34,186 - INFO - tqdm - coref_precision: 0.9334, coref_recall: 0.7679, coref_f1: 0.8346, mention_recall: 0.9865, batch_loss: 0.0323, loss: 5.2170 ||:  52%|#####2    | 523/998 [01:01<01:05,  7.30it/s]
2022-05-15 02:08:44,224 - INFO - tqdm - coref_precision: 0.9313, coref_recall: 0.7671, coref_f1: 0.8336, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.0759 ||:  61%|######1   | 612/998 [01:11<01:09,  5.59it/s]
2022-05-15 02:08:54,596 - INFO - tqdm - coref_precision: 0.9308, coref_recall: 0.7680, coref_f1: 0.8338, mention_recall: 0.9870, batch_loss: 16.6263, loss: 4.9190 ||:  69%|######8   | 688/998 [01:22<01:01,  5.03it/s]
2022-05-15 02:09:04,700 - INFO - tqdm - coref_precision: 0.9333, coref_recall: 0.7689, coref_f1: 0.8351, mention_recall: 0.9873, batch_loss: 0.0000, loss: 4.6777 ||:  78%|#######8  | 782/998 [01:32<00:23,  9.23it/s]
2022-05-15 02:09:14,858 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7672, coref_f1: 0.8341, mention_recall: 0.9879, batch_loss: 0.0000, loss: 5.3050 ||:  87%|########7 | 870/998 [01:42<00:14,  8.76it/s]
2022-05-15 02:09:25,012 - INFO - tqdm - coref_precision: 0.9335, coref_recall: 0.7685, coref_f1: 0.8350, mention_recall: 0.9878, batch_loss: 0.0000, loss: 5.1692 ||:  96%|#########6| 963/998 [01:52<00:03, 10.86it/s]
2022-05-15 02:09:29,049 - INFO - tqdm - coref_precision: 0.9333, coref_recall: 0.7681, coref_f1: 0.8346, mention_recall: 0.9876, batch_loss: 0.0000, loss: 5.1404 ||: 100%|#########9| 995/998 [01:56<00:00, 11.10it/s]
2022-05-15 02:09:29,468 - INFO - tqdm - coref_precision: 0.9330, coref_recall: 0.7676, coref_f1: 0.8343, mention_recall: 0.9876, batch_loss: 0.0000, loss: 5.1362 ||: 100%|#########9| 997/998 [01:57<00:00,  7.89it/s]
2022-05-15 02:09:29,535 - INFO - tqdm - coref_precision: 0.9330, coref_recall: 0.7677, coref_f1: 0.8343, mention_recall: 0.9876, batch_loss: 0.0000, loss: 5.1311 ||: 100%|##########| 998/998 [01:57<00:00,  8.52it/s]
2022-05-15 02:09:30,483 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:09:30,484 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:09:37,161 - INFO - tqdm - coref_precision: 0.6497, coref_recall: 0.5086, coref_f1: 0.5635, mention_recall: 0.9760, batch_loss: 54.6930, loss: 97.8315 ||: 100%|##########| 122/122 [00:06<00:00, 18.27it/s]
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.834  |     0.564
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.933  |     0.650
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.768  |     0.509
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.131  |    97.831
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.976
2022-05-15 02:09:39,235 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:09:39,235 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.806548
2022-05-15 02:09:39,235 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:28:15
2022-05-15 02:09:39,235 - INFO - allennlp.training.trainer - Epoch 25/149
2022-05-15 02:09:39,235 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:09:39,236 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:09:39,237 - INFO - allennlp.training.trainer - Training
2022-05-15 02:09:39,237 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:09:49,409 - INFO - tqdm - coref_precision: 0.9310, coref_recall: 0.7816, coref_f1: 0.8452, mention_recall: 0.9872, batch_loss: 20.9586, loss: 3.4601 ||:   8%|7         | 78/998 [00:10<01:50,  8.32it/s]
2022-05-15 02:09:59,449 - INFO - tqdm - coref_precision: 0.9426, coref_recall: 0.7798, coref_f1: 0.8460, mention_recall: 0.9885, batch_loss: 2.3613, loss: 3.4932 ||:  16%|#5        | 158/998 [00:20<01:45,  7.94it/s]
2022-05-15 02:10:09,472 - INFO - tqdm - coref_precision: 0.9301, coref_recall: 0.7632, coref_f1: 0.8311, mention_recall: 0.9882, batch_loss: 0.0000, loss: 6.5566 ||:  26%|##6       | 260/998 [00:30<01:36,  7.67it/s]
2022-05-15 02:10:20,024 - INFO - tqdm - coref_precision: 0.9301, coref_recall: 0.7639, coref_f1: 0.8312, mention_recall: 0.9877, batch_loss: 24.5480, loss: 6.0771 ||:  34%|###4      | 343/998 [00:40<01:55,  5.68it/s]
2022-05-15 02:10:30,158 - INFO - tqdm - coref_precision: 0.9345, coref_recall: 0.7760, coref_f1: 0.8402, mention_recall: 0.9874, batch_loss: 0.6538, loss: 5.5015 ||:  44%|####3     | 435/998 [00:50<01:12,  7.73it/s]
2022-05-15 02:10:40,267 - INFO - tqdm - coref_precision: 0.9368, coref_recall: 0.7800, coref_f1: 0.8432, mention_recall: 0.9870, batch_loss: 0.0000, loss: 4.8781 ||:  53%|#####2    | 525/998 [01:01<00:52,  8.96it/s]
2022-05-15 02:10:50,421 - INFO - tqdm - coref_precision: 0.9333, coref_recall: 0.7802, coref_f1: 0.8418, mention_recall: 0.9863, batch_loss: 271.6791, loss: 4.8263 ||:  61%|######1   | 613/998 [01:11<02:03,  3.11it/s]
2022-05-15 02:11:00,437 - INFO - tqdm - coref_precision: 0.9331, coref_recall: 0.7775, coref_f1: 0.8402, mention_recall: 0.9868, batch_loss: 0.0001, loss: 4.7726 ||:  69%|######8   | 688/998 [01:21<00:32,  9.59it/s]
2022-05-15 02:11:10,542 - INFO - tqdm - coref_precision: 0.9246, coref_recall: 0.7674, coref_f1: 0.8312, mention_recall: 0.9872, batch_loss: 0.0000, loss: 5.7915 ||:  77%|#######7  | 770/998 [01:31<00:20, 11.20it/s]
2022-05-15 02:11:20,592 - INFO - tqdm - coref_precision: 0.9281, coref_recall: 0.7715, coref_f1: 0.8348, mention_recall: 0.9870, batch_loss: 0.0000, loss: 5.4245 ||:  86%|########5 | 855/998 [01:41<00:17,  8.39it/s]
2022-05-15 02:11:30,976 - INFO - tqdm - coref_precision: 0.9292, coref_recall: 0.7686, coref_f1: 0.8332, mention_recall: 0.9872, batch_loss: 1.6635, loss: 5.4147 ||:  94%|#########3| 938/998 [01:51<00:09,  6.12it/s]
2022-05-15 02:11:35,912 - INFO - tqdm - coref_precision: 0.9311, coref_recall: 0.7713, coref_f1: 0.8355, mention_recall: 0.9873, batch_loss: 19.1961, loss: 5.1597 ||: 100%|#########9| 995/998 [01:56<00:00, 11.43it/s]
2022-05-15 02:11:36,050 - INFO - tqdm - coref_precision: 0.9311, coref_recall: 0.7713, coref_f1: 0.8355, mention_recall: 0.9873, batch_loss: 0.0000, loss: 5.1493 ||: 100%|#########9| 997/998 [01:56<00:00, 12.21it/s]
2022-05-15 02:11:36,113 - INFO - tqdm - coref_precision: 0.9311, coref_recall: 0.7713, coref_f1: 0.8355, mention_recall: 0.9873, batch_loss: 0.0000, loss: 5.1441 ||: 100%|##########| 998/998 [01:56<00:00,  8.54it/s]
2022-05-15 02:11:37,063 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:11:37,065 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:11:43,723 - INFO - tqdm - coref_precision: 0.6496, coref_recall: 0.5013, coref_f1: 0.5586, mention_recall: 0.9738, batch_loss: 0.0005, loss: 97.4889 ||: 100%|##########| 122/122 [00:06<00:00, 18.32it/s]
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.835  |     0.559
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.931  |     0.650
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.771  |     0.501
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - loss               |     5.144  |    97.489
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.987  |     0.974
2022-05-15 02:11:45,799 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:11:45,799 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.563972
2022-05-15 02:11:45,800 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:25:56
2022-05-15 02:11:45,800 - INFO - allennlp.training.trainer - Epoch 26/149
2022-05-15 02:11:45,800 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:11:45,800 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:11:45,801 - INFO - allennlp.training.trainer - Training
2022-05-15 02:11:45,801 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:11:56,610 - INFO - tqdm - coref_precision: 0.9665, coref_recall: 0.8188, coref_f1: 0.8776, mention_recall: 0.9802, batch_loss: 0.0000, loss: 1.0132 ||:   9%|9         | 91/998 [00:10<05:26,  2.78it/s]
2022-05-15 02:12:06,706 - INFO - tqdm - coref_precision: 0.9593, coref_recall: 0.8159, coref_f1: 0.8724, mention_recall: 0.9843, batch_loss: 0.0000, loss: 1.7258 ||:  18%|#7        | 177/998 [00:20<01:48,  7.57it/s]
2022-05-15 02:12:16,824 - INFO - tqdm - coref_precision: 0.9397, coref_recall: 0.7768, coref_f1: 0.8417, mention_recall: 0.9852, batch_loss: 0.0000, loss: 5.4685 ||:  27%|##6       | 265/998 [00:31<01:18,  9.30it/s]
2022-05-15 02:12:26,956 - INFO - tqdm - coref_precision: 0.9399, coref_recall: 0.7817, coref_f1: 0.8444, mention_recall: 0.9849, batch_loss: 1.0760, loss: 4.9635 ||:  34%|###4      | 341/998 [00:41<01:36,  6.80it/s]
2022-05-15 02:12:37,087 - INFO - tqdm - coref_precision: 0.9383, coref_recall: 0.7800, coref_f1: 0.8430, mention_recall: 0.9852, batch_loss: -0.0000, loss: 4.8796 ||:  43%|####3     | 433/998 [00:51<00:50, 11.24it/s]
2022-05-15 02:12:47,124 - INFO - tqdm - coref_precision: 0.9406, coref_recall: 0.7843, coref_f1: 0.8462, mention_recall: 0.9851, batch_loss: 0.1229, loss: 4.3772 ||:  53%|#####3    | 533/998 [01:01<01:09,  6.73it/s]
2022-05-15 02:12:57,438 - INFO - tqdm - coref_precision: 0.9344, coref_recall: 0.7699, coref_f1: 0.8352, mention_recall: 0.9851, batch_loss: 5.0813, loss: 5.3368 ||:  63%|######2   | 628/998 [01:11<01:01,  5.97it/s]
2022-05-15 02:13:08,504 - INFO - tqdm - coref_precision: 0.9308, coref_recall: 0.7689, coref_f1: 0.8334, mention_recall: 0.9853, batch_loss: 123.6607, loss: 5.3165 ||:  71%|#######   | 708/998 [01:22<01:43,  2.80it/s]
2022-05-15 02:13:18,621 - INFO - tqdm - coref_precision: 0.9332, coref_recall: 0.7720, coref_f1: 0.8363, mention_recall: 0.9859, batch_loss: 0.0000, loss: 5.0111 ||:  79%|#######9  | 791/998 [01:32<00:24,  8.36it/s]
2022-05-15 02:13:28,845 - INFO - tqdm - coref_precision: 0.9353, coref_recall: 0.7749, coref_f1: 0.8388, mention_recall: 0.9860, batch_loss: 0.0874, loss: 4.7486 ||:  89%|########8 | 887/998 [01:43<00:10, 10.62it/s]
2022-05-15 02:13:38,940 - INFO - tqdm - coref_precision: 0.9302, coref_recall: 0.7695, coref_f1: 0.8338, mention_recall: 0.9862, batch_loss: 59.4452, loss: 4.9403 ||:  97%|#########6| 968/998 [01:53<00:06,  4.52it/s]
2022-05-15 02:13:42,339 - INFO - tqdm - coref_precision: 0.9297, coref_recall: 0.7689, coref_f1: 0.8333, mention_recall: 0.9862, batch_loss: 0.0000, loss: 4.9566 ||: 100%|#########9| 994/998 [01:56<00:00, 10.49it/s]
2022-05-15 02:13:42,575 - INFO - tqdm - coref_precision: 0.9297, coref_recall: 0.7692, coref_f1: 0.8335, mention_recall: 0.9863, batch_loss: 2.0450, loss: 4.9487 ||: 100%|#########9| 996/998 [01:56<00:00,  9.76it/s]
2022-05-15 02:13:42,757 - INFO - tqdm - coref_precision: 0.9298, coref_recall: 0.7693, coref_f1: 0.8336, mention_recall: 0.9863, batch_loss: 0.0000, loss: 4.9388 ||: 100%|##########| 998/998 [01:56<00:00, 10.11it/s]
2022-05-15 02:13:42,758 - INFO - tqdm - coref_precision: 0.9298, coref_recall: 0.7693, coref_f1: 0.8336, mention_recall: 0.9863, batch_loss: 0.0000, loss: 4.9388 ||: 100%|##########| 998/998 [01:56<00:00,  8.53it/s]
2022-05-15 02:13:43,705 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:13:43,706 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:13:50,373 - INFO - tqdm - coref_precision: 0.6514, coref_recall: 0.5009, coref_f1: 0.5595, mention_recall: 0.9755, batch_loss: 14.2142, loss: 101.5478 ||: 100%|##########| 122/122 [00:06<00:00, 18.30it/s]
2022-05-15 02:13:52,449 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.834  |     0.560
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.930  |     0.651
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.769  |     0.501
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - loss               |     4.939  |   101.548
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.986  |     0.975
2022-05-15 02:13:52,451 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7599.969  |       N/A
2022-05-15 02:13:52,452 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.651973
2022-05-15 02:13:52,452 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:23:38
2022-05-15 02:13:52,452 - INFO - allennlp.training.trainer - Epoch 27/149
2022-05-15 02:13:52,452 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:13:52,452 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:13:52,453 - INFO - allennlp.training.trainer - Training
2022-05-15 02:13:52,453 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:14:02,460 - INFO - tqdm - coref_precision: 0.8944, coref_recall: 0.7518, coref_f1: 0.8120, mention_recall: 0.9906, batch_loss: 5.4365, loss: 7.8427 ||:   7%|7         | 73/998 [00:10<01:37,  9.51it/s]
2022-05-15 02:14:12,583 - INFO - tqdm - coref_precision: 0.9165, coref_recall: 0.7636, coref_f1: 0.8266, mention_recall: 0.9905, batch_loss: 0.0000, loss: 5.5978 ||:  15%|#4        | 148/998 [00:20<01:25,  9.97it/s]
2022-05-15 02:14:22,730 - INFO - tqdm - coref_precision: 0.9254, coref_recall: 0.7694, coref_f1: 0.8334, mention_recall: 0.9899, batch_loss: 0.0175, loss: 4.3692 ||:  24%|##3       | 235/998 [00:30<01:58,  6.44it/s]
2022-05-15 02:14:32,828 - INFO - tqdm - coref_precision: 0.9289, coref_recall: 0.7669, coref_f1: 0.8324, mention_recall: 0.9879, batch_loss: 0.0000, loss: 4.4416 ||:  33%|###2      | 326/998 [00:40<01:19,  8.43it/s]
2022-05-15 02:14:42,975 - INFO - tqdm - coref_precision: 0.9269, coref_recall: 0.7685, coref_f1: 0.8321, mention_recall: 0.9876, batch_loss: 16.5014, loss: 4.4822 ||:  41%|####1     | 413/998 [00:50<01:14,  7.84it/s]
2022-05-15 02:14:53,264 - INFO - tqdm - coref_precision: 0.9245, coref_recall: 0.7604, coref_f1: 0.8267, mention_recall: 0.9883, batch_loss: 0.3829, loss: 5.8994 ||:  50%|#####     | 499/998 [01:00<00:54,  9.10it/s]
2022-05-15 02:15:03,768 - INFO - tqdm - coref_precision: 0.9292, coref_recall: 0.7655, coref_f1: 0.8315, mention_recall: 0.9882, batch_loss: 16.8107, loss: 5.0816 ||:  60%|######    | 600/998 [01:11<01:18,  5.05it/s]
2022-05-15 02:15:13,947 - INFO - tqdm - coref_precision: 0.9338, coref_recall: 0.7722, coref_f1: 0.8371, mention_recall: 0.9876, batch_loss: 0.0000, loss: 4.5355 ||:  71%|#######   | 706/998 [01:21<00:29,  9.93it/s]
2022-05-15 02:15:24,133 - INFO - tqdm - coref_precision: 0.9288, coref_recall: 0.7650, coref_f1: 0.8311, mention_recall: 0.9881, batch_loss: 0.0000, loss: 5.3890 ||:  79%|#######8  | 786/998 [01:31<00:22,  9.24it/s]
2022-05-15 02:15:34,488 - INFO - tqdm - coref_precision: 0.9298, coref_recall: 0.7666, coref_f1: 0.8324, mention_recall: 0.9878, batch_loss: 130.7812, loss: 5.1728 ||:  88%|########7 | 874/998 [01:42<00:25,  4.92it/s]
2022-05-15 02:15:44,584 - INFO - tqdm - coref_precision: 0.9316, coref_recall: 0.7709, coref_f1: 0.8356, mention_recall: 0.9876, batch_loss: 0.0000, loss: 5.0611 ||:  95%|#########5| 952/998 [01:52<00:05,  7.68it/s]
2022-05-15 02:15:49,154 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7722, coref_f1: 0.8369, mention_recall: 0.9875, batch_loss: 0.0001, loss: 4.9183 ||: 100%|#########9| 994/998 [01:56<00:00,  8.29it/s]
2022-05-15 02:15:49,270 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7723, coref_f1: 0.8369, mention_recall: 0.9875, batch_loss: 0.0000, loss: 4.9084 ||: 100%|#########9| 996/998 [01:56<00:00,  9.82it/s]
2022-05-15 02:15:49,393 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7722, coref_f1: 0.8368, mention_recall: 0.9875, batch_loss: 0.0000, loss: 4.8986 ||: 100%|##########| 998/998 [01:56<00:00, 11.15it/s]
2022-05-15 02:15:49,394 - INFO - tqdm - coref_precision: 0.9327, coref_recall: 0.7722, coref_f1: 0.8368, mention_recall: 0.9875, batch_loss: 0.0000, loss: 4.8986 ||: 100%|##########| 998/998 [01:56<00:00,  8.53it/s]
2022-05-15 02:15:50,335 - INFO - allennlp.training.trainer - Validating
2022-05-15 02:15:50,337 - INFO - tqdm - 0%|          | 0/122 [00:00<?, ?it/s]
2022-05-15 02:15:57,006 - INFO - tqdm - coref_precision: 0.6557, coref_recall: 0.4998, coref_f1: 0.5604, mention_recall: 0.9744, batch_loss: 249.9747, loss: 100.8834 ||: 100%|##########| 122/122 [00:06<00:00, 20.40it/s]
2022-05-15 02:15:57,006 - INFO - tqdm - coref_precision: 0.6557, coref_recall: 0.4998, coref_f1: 0.5604, mention_recall: 0.9744, batch_loss: 249.9747, loss: 100.8834 ||: 100%|##########| 122/122 [00:06<00:00, 18.29it/s]
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - coref_f1           |     0.837  |     0.560
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - coref_precision    |     0.933  |     0.656
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - coref_recall       |     0.772  |     0.500
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |  37463.900  |       N/A
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - loss               |     4.899  |   100.883
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - mention_recall     |     0.988  |     0.974
2022-05-15 02:15:59,081 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7600.219  |       N/A
2022-05-15 02:15:59,081 - INFO - allennlp.training.trainer - Epoch duration: 0:02:06.629642
2022-05-15 02:15:59,081 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:21:20
2022-05-15 02:15:59,081 - INFO - allennlp.training.trainer - Epoch 28/149
2022-05-15 02:15:59,082 - INFO - allennlp.training.trainer - Worker 0 memory usage: 7.4G
2022-05-15 02:15:59,082 - INFO - allennlp.training.trainer - GPU 0 memory usage: 37G
2022-05-15 02:15:59,083 - INFO - allennlp.training.trainer - Training
2022-05-15 02:15:59,083 - INFO - tqdm - 0%|          | 0/998 [00:00<?, ?it/s]
2022-05-15 02:16:06,460 - INFO - root - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
2022-05-15 02:16:06,460 - INFO - allennlp.models.archival - archiving weights and vocabulary to rucoref_model_trained/model.tar.gz
